{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet classification\n",
    "\n",
    "File names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read\n",
    "test_tweets_raw = 'datasets/test_nolabel.csv'\n",
    "train_tweets_raw = 'datasets/train.csv'\n",
    "corpus_tweets_2012_xml = 'general-train-tagged-3l.xml'\n",
    "corpus_tweets_2017_xml = 'intertass-train-tagged.xml'\n",
    "emojis_csv = 'emojis.csv'\n",
    "\n",
    "# To generate\n",
    "corpus_tweets_2012_csv = 'general-train-tagged-3l.csv'\n",
    "corpus_tweets_2017_csv = 'intertass-train-tagged.csv'\n",
    "corpus_tweets_csv = 'corpus_tweets_prprocessed.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Pandas and Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets to evaluate: 177\n",
      "Evaluated tweets so far: 411\n"
     ]
    }
   ],
   "source": [
    "tweets_test = pd.read_csv(test_tweets_raw, encoding='utf-8')\n",
    "tweets_train = pd.read_csv(train_tweets_raw, encoding='utf-8')\n",
    "\n",
    "print('Total tweets to evaluate: %d' % len(tweets_test))\n",
    "print('Evaluated tweets so far: %d' % len(tweets_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging\n",
    "\n",
    "Import libraries to read XML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import objectify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import/read most recent corpus (2017):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 values of sentiment: N, P, NONE, NEU\n",
    "xml = objectify.parse(open(corpus_tweets_2017_xml))\n",
    "root = xml.getroot()\n",
    "general_tweets_corpus_train_2017 = pd.DataFrame(columns=('content', 'polarity'))\n",
    "tweets = root.getchildren()\n",
    "for i in range(0, len(tweets)):\n",
    "    tweet = tweets[i]\n",
    "    row = dict(zip(['content', 'polarity'], [tweet.content.text, tweet.sentiment.polarity.value.text]))\n",
    "    row_s = pd.Series(row)\n",
    "    row_s.name = i\n",
    "    general_tweets_corpus_train_2017 = general_tweets_corpus_train_2017.append(row_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import/read biggest corpus (2012), to concatenate it with the previous one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 values of sentiment: N, P, NONE, NEU\n",
    "xml = objectify.parse(open(corpus_tweets_2012_xml))\n",
    "root = xml.getroot()\n",
    "general_tweets_corpus_train_2012 = pd.DataFrame(columns=('content', 'polarity'))\n",
    "tweets = root.getchildren()\n",
    "for i in range(0, len(tweets)):\n",
    "    tweet = tweets[i]\n",
    "    row = dict(zip(['content', 'polarity'], [tweet.content.text, tweet.sentiments.polarity.value.text]))\n",
    "    row_s = pd.Series(row)\n",
    "    row_s.name = i\n",
    "    general_tweets_corpus_train_2012 = general_tweets_corpus_train_2012.append(row_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import/read emoji sentiment dataset, to concatenate with the previous ones. Build column `polarity` according to the following criteria:\n",
    "- If sentiment score is between -1 and -0.2, consider it a **negative** sentiment (`N`).\n",
    "- If sentiment score is between -0.2 and 0.2, consider it a **neutral** sentiment (`NEU`).\n",
    "- If sentiment score is between 0.2 and 1, consider it a **positive** sentiment (`P`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angel.munozs/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/angel.munozs/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# Read emojis CSV\n",
    "emoji_dataset = pd.read_csv(emojis_csv, encoding='utf-8')\n",
    "\n",
    "# Init dataframe to append to corpus\n",
    "emoji_corpus = pd.DataFrame(columns=('content', 'polarity'))\n",
    "\n",
    "# Build column 'polarity\n",
    "emoji_dataset['polarity'] = 'NEU'\n",
    "emoji_dataset['polarity'][emoji_dataset.sentiment < -0.2] = 'N'\n",
    "emoji_dataset['polarity'][emoji_dataset.sentiment > 0.2] = 'P'\n",
    "\n",
    "for i, row in emoji_dataset.iterrows():\n",
    "    new_row = dict(zip(['content', 'polarity'], [chr(int(row.emoji, 16)), row.polarity]))\n",
    "    row_s = pd.Series(new_row)\n",
    "    row_s.name = i\n",
    "    emoji_corpus = emoji_corpus.append(row_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate general corpus dataset with 2017 one, to have a better result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus = pd.concat([\n",
    "        general_tweets_corpus_train_2012,\n",
    "        general_tweets_corpus_train_2017,\n",
    "        emoji_corpus\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build emojis regex\n",
    "import re\n",
    "emoji_regex = re.compile(r'[%s]' % (''.join(emoji_corpus['content'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4242</th>\n",
       "      <td>@estherpalomera se sabe qui√©n comparece por pa...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3845</th>\n",
       "      <td>Aqu√≠ ten√©is un v√≠deo de mi amigo Pinto Colorad...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6660</th>\n",
       "      <td>Como siempre, hay quien intenta manchar el √©xi...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Accidente en BUS-VAO A-6 km. 12. Motorista de ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5049</th>\n",
       "      <td>Periodistas de informativos T5 agredidos ayer,...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>Buenos d√≠as Magaluf !  üëåüèª‚úÖ\\n‚Ä¢ @BHmallorca ‚Ä¢ #B...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>üòÄ</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>http://t.co/FUleUc9K</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>Curiosa imagen veremos ma√±ana. El Ministro Ca√±...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5590</th>\n",
       "      <td>Primero se les trata de vividores, luego  de v...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content polarity\n",
       "4242  @estherpalomera se sabe qui√©n comparece por pa...     NONE\n",
       "3845  Aqu√≠ ten√©is un v√≠deo de mi amigo Pinto Colorad...        P\n",
       "6660  Como siempre, hay quien intenta manchar el √©xi...        N\n",
       "23    Accidente en BUS-VAO A-6 km. 12. Motorista de ...        N\n",
       "5049  Periodistas de informativos T5 agredidos ayer,...        N\n",
       "768   Buenos d√≠as Magaluf !  üëåüèª‚úÖ\\n‚Ä¢ @BHmallorca ‚Ä¢ #B...        P\n",
       "67                                                    üòÄ        P\n",
       "3917                               http://t.co/FUleUc9K     NONE\n",
       "2501  Curiosa imagen veremos ma√±ana. El Ministro Ca√±...     NONE\n",
       "5590  Primero se les trata de vividores, luego  de v...        N"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus tweets: 8978\n"
     ]
    }
   ],
   "source": [
    "print('Total corpus tweets: %d' % len(tweets_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove tweets from the corpus where `polarity` is `NONE`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove tweets with polarity 'NONE'\n",
    "tweets_corpus = tweets_corpus.query('polarity != \"NONE\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "\n",
    "First, we define some cleaning functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean tweets tools\n",
    "from cleaner import clean_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we clean the train and test data with the previous function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus = clean_tweets(tweets_corpus, 'content', emoji_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus tweets after cleaning: 7356\n"
     ]
    }
   ],
   "source": [
    "print('Total corpus tweets after cleaning: %d' % len(tweets_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4642</th>\n",
       "      <td>. llama a la regeneraci√≥n en #Andaluc√≠a frente...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>La vida nos lleva por caminos inextricables j...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>‚í∫</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>+1 RT :que entreguen las armas, que se entregu...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5016</th>\n",
       "      <td>Una de fakes de esos que todos los medios nos ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>EL BARRIO en : \"C√°diz es tierra de embajadores...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5938</th>\n",
       "      <td>Y a ti ;-)) RT : Cont√°ndote a ti :-) RT : Qu√© ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4218</th>\n",
       "      <td>\"Redacci√≥n simulada\" para aprender periodismo ...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>el s√°bado unas risas todos juntos... A por ot...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2 horas esperando en Comisar√≠a Gandia y han a...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content polarity\n",
       "4642  . llama a la regeneraci√≥n en #Andaluc√≠a frente...        N\n",
       "714    La vida nos lleva por caminos inextricables j...        P\n",
       "720                                                   ‚í∫        P\n",
       "695   +1 RT :que entreguen las armas, que se entregu...        N\n",
       "5016  Una de fakes de esos que todos los medios nos ...        N\n",
       "2999  EL BARRIO en : \"C√°diz es tierra de embajadores...        N\n",
       "5938  Y a ti ;-)) RT : Cont√°ndote a ti :-) RT : Qu√© ...        P\n",
       "4218  \"Redacci√≥n simulada\" para aprender periodismo ...      NEU\n",
       "720    el s√°bado unas risas todos juntos... A por ot...        P\n",
       "27     2 horas esperando en Comisar√≠a Gandia y han a...        N"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export corpus tweets as CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus.to_csv(corpus_tweets_csv, encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
