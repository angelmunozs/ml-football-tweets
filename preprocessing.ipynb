{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet classification\n",
    "\n",
    "File names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read\n",
    "test_tweets_raw = 'datasets/test_nolabel.csv'\n",
    "train_tweets_raw = 'datasets/train.csv'\n",
    "corpus_tweets_2012_xml = 'general-train-tagged-3l.xml'\n",
    "corpus_tweets_2017_xml = 'intertass-train-tagged.xml'\n",
    "\n",
    "# To generate\n",
    "corpus_tweets_2012_csv = 'general-train-tagged-3l.csv'\n",
    "corpus_tweets_2017_csv = 'intertass-train-tagged.csv'\n",
    "corpus_tweets_csv = 'corpus_tweets_prprocessed.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Pandas and Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets to evaluate: 177\n",
      "Evaluated tweets so far: 411\n"
     ]
    }
   ],
   "source": [
    "tweets_test = pd.read_csv(test_tweets_raw, encoding='utf-8')\n",
    "tweets_train = pd.read_csv(train_tweets_raw, encoding='utf-8')\n",
    "\n",
    "print('Total tweets to evaluate: %d' % len(tweets_test))\n",
    "print('Evaluated tweets so far: %d' % len(tweets_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging\n",
    "\n",
    "Import libraries to read XML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import objectify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import/read most recent corpus (2017):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 values of sentiment: N, P, NONE, NEU\n",
    "xml = objectify.parse(open(corpus_tweets_2017_xml))\n",
    "root = xml.getroot()\n",
    "general_tweets_corpus_train_2017 = pd.DataFrame(columns=('content', 'polarity'))\n",
    "tweets = root.getchildren()\n",
    "for i in range(0, len(tweets)):\n",
    "    tweet = tweets[i]\n",
    "    row = dict(zip(['content', 'polarity'], [tweet.content.text, tweet.sentiment.polarity.value.text]))\n",
    "    row_s = pd.Series(row)\n",
    "    row_s.name = i\n",
    "    general_tweets_corpus_train_2017 = general_tweets_corpus_train_2017.append(row_s)\n",
    "    \n",
    "general_tweets_corpus_train_2017.to_csv(corpus_tweets_2017_csv, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import/read biggest corpus (2012), to concatenate it with the previous one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 values of sentiment: N, P, NONE, NEU\n",
    "xml = objectify.parse(open(corpus_tweets_2012_xml))\n",
    "root = xml.getroot()\n",
    "general_tweets_corpus_train_2012 = pd.DataFrame(columns=('content', 'polarity'))\n",
    "tweets = root.getchildren()\n",
    "for i in range(0, len(tweets)):\n",
    "    tweet = tweets[i]\n",
    "    row = dict(zip(['content', 'polarity'], [tweet.content.text, tweet.sentiments.polarity.value.text]))\n",
    "    row_s = pd.Series(row)\n",
    "    row_s.name = i\n",
    "    general_tweets_corpus_train_2012 = general_tweets_corpus_train_2012.append(row_s)\n",
    "    \n",
    "general_tweets_corpus_train_2012.to_csv(corpus_tweets_2012_csv, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate general corpus dataset with 2017 one, to have a better result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4917</th>\n",
       "      <td>2011: la circulación agregada de los diarios d...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5829</th>\n",
       "      <td>Genial J.Coll haciendo pedagogía vs mentira dl...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>Con el PSOE Extremadura formaba parte de la ca...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>Si, soy democrata radical y ellos no condenan ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>Durao Barroso pide a Raoy que explique cuanto ...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Bdías. Que el Reino Unido se quede fuera indic...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>Curioso. Al de Amaiur no le han aplaudido ni l...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5274</th>\n",
       "      <td>Buenos días, hoy en Sevilla firmamos el conven...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Por desgracia el sorteo que tenía pensado hace...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Menudo break en blanco ha logrado DelPotro. Va...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content polarity\n",
       "4917  2011: la circulación agregada de los diarios d...        N\n",
       "5829  Genial J.Coll haciendo pedagogía vs mentira dl...        N\n",
       "3254  Con el PSOE Extremadura formaba parte de la ca...      NEU\n",
       "661   Si, soy democrata radical y ellos no condenan ...        N\n",
       "3231  Durao Barroso pide a Raoy que explique cuanto ...     NONE\n",
       "333   Bdías. Que el Reino Unido se quede fuera indic...        P\n",
       "1043  Curioso. Al de Amaiur no le han aplaudido ni l...        N\n",
       "5274  Buenos días, hoy en Sevilla firmamos el conven...        P\n",
       "70    Por desgracia el sorteo que tenía pensado hace...        N\n",
       "136   Menudo break en blanco ha logrado DelPotro. Va...      NEU"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus = pd.concat([\n",
    "        general_tweets_corpus_train_2012,\n",
    "        general_tweets_corpus_train_2017\n",
    "    ])\n",
    "tweets_corpus.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus tweets: 8227\n"
     ]
    }
   ],
   "source": [
    "print('Total corpus tweets: %d' % len(tweets_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove twets from the corpus where `polarity` is `NONE`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove tweets with polarity 'NONE'\n",
    "tweets_corpus = tweets_corpus.query('polarity != \"NONE\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "\n",
    "First, we define some cleaning functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean tweets tools\n",
    "from cleaner import clean_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we clean the train and test data with the previous function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus = clean_tweets(tweets_corpus, 'content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus tweets after cleaning: 6605\n"
     ]
    }
   ],
   "source": [
    "print('Total corpus tweets after cleaning: %d' % len(tweets_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5129</th>\n",
       "      <td>” POLONIA D AYER. Primer gag, nuevo personaje ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3865</th>\n",
       "      <td>Uyy que se me olvidaba dejaros esta pagina par...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6503</th>\n",
       "      <td>. \" en  Andalucía a través de las urnas es pos...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5636</th>\n",
       "      <td>Gracias  VisitaElHierro RT : Para los que no s...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>Encuesta cachonda en la web dl PSOE-A: Ves jus...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>Se ha montado la de Dios! A ver: habrá que sor...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>FF para . Ella ya sabe...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6275</th>\n",
       "      <td>Sólo Grecia, Malta, Chipre y España no tienen ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Confirmao tengo el pie roto, he notado como el...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Preciosa de verdad - Perdóname by Pablo Alborá...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content polarity\n",
       "5129  ” POLONIA D AYER. Primer gag, nuevo personaje ...        P\n",
       "3865  Uyy que se me olvidaba dejaros esta pagina par...      NEU\n",
       "6503  . \" en  Andalucía a través de las urnas es pos...        P\n",
       "5636  Gracias  VisitaElHierro RT : Para los que no s...        P\n",
       "4600  Encuesta cachonda en la web dl PSOE-A: Ves jus...      NEU\n",
       "1821  Se ha montado la de Dios! A ver: habrá que sor...        N\n",
       "349                           FF para . Ella ya sabe...        P\n",
       "6275  Sólo Grecia, Malta, Chipre y España no tienen ...        N\n",
       "37    Confirmao tengo el pie roto, he notado como el...        N\n",
       "108   Preciosa de verdad - Perdóname by Pablo Alborá...        P"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export corpus tweets as CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus.to_csv(corpus_tweets_csv, encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
