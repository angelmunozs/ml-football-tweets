{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet classification\n",
    "\n",
    "File names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read\n",
    "test_tweets_raw = 'datasets/test_nolabel.csv'\n",
    "train_tweets_raw = 'datasets/train.csv'\n",
    "corpus_tweets_2012_xml = 'general-train-tagged-3l.xml'\n",
    "corpus_tweets_2017_xml = 'intertass-train-tagged.xml'\n",
    "emojis_csv = 'emojis.csv'\n",
    "\n",
    "# To generate\n",
    "corpus_tweets_2012_csv = 'general-train-tagged-3l.csv'\n",
    "corpus_tweets_2017_csv = 'intertass-train-tagged.csv'\n",
    "corpus_tweets_csv = 'corpus_tweets_preprocessed.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Pandas and Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets to evaluate: 177\n",
      "Evaluated tweets so far: 411\n"
     ]
    }
   ],
   "source": [
    "tweets_test = pd.read_csv(test_tweets_raw, encoding='utf-8')\n",
    "tweets_train = pd.read_csv(train_tweets_raw, encoding='utf-8')\n",
    "\n",
    "print('Total tweets to evaluate: %d' % len(tweets_test))\n",
    "print('Evaluated tweets so far: %d' % len(tweets_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging\n",
    "\n",
    "Import libraries to read XML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import objectify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import/read most recent corpus (2017):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 values of sentiment: N, P, NONE, NEU\n",
    "xml = objectify.parse(open(corpus_tweets_2017_xml))\n",
    "root = xml.getroot()\n",
    "general_tweets_corpus_train_2017 = pd.DataFrame(columns=('content', 'polarity'))\n",
    "tweets = root.getchildren()\n",
    "for i in range(0, len(tweets)):\n",
    "    tweet = tweets[i]\n",
    "    row = dict(zip(['content', 'polarity'], [tweet.content.text, tweet.sentiment.polarity.value.text]))\n",
    "    row_s = pd.Series(row)\n",
    "    row_s.name = i\n",
    "    general_tweets_corpus_train_2017 = general_tweets_corpus_train_2017.append(row_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N       418\n",
       "P       318\n",
       "NONE    139\n",
       "NEU     133\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_tweets_corpus_train_2017.polarity.value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of tweets to remove\n",
    "positive_to_remove = 318-133\n",
    "negative_to_remove = 418-133\n",
    "positive_removed = 0\n",
    "negative_removed = 0\n",
    "\n",
    "# Init balanced version\n",
    "general_tweets_corpus_train_2017_balanced = pd.DataFrame(columns=('content', 'polarity'))\n",
    "\n",
    "# We balance the dataset, to have the same number of positive, negative and neutral polarity\n",
    "for i, row in general_tweets_corpus_train_2017.iterrows():\n",
    "    if(row.polarity) == 'P':\n",
    "        positive_removed = positive_removed + 1\n",
    "        if(positive_removed > positive_to_remove):\n",
    "            row_p = dict(zip(['content', 'polarity'], [row.content, row.polarity]))\n",
    "            row_s = pd.Series(row_p)\n",
    "            row_s.name = i\n",
    "            general_tweets_corpus_train_2017_balanced = general_tweets_corpus_train_2017_balanced.append(row_s)\n",
    "    if(row.polarity) == 'N':\n",
    "        negative_removed = negative_removed + 1\n",
    "        if(negative_removed > negative_to_remove):\n",
    "            row_p = dict(zip(['content', 'polarity'], [row.content, row.polarity]))\n",
    "            row_s = pd.Series(row_p)\n",
    "            row_s.name = i\n",
    "            general_tweets_corpus_train_2017_balanced = general_tweets_corpus_train_2017_balanced.append(row_s)\n",
    "    if(row.polarity) == 'NEU':\n",
    "        row_p = dict(zip(['content', 'polarity'], [row.content, row.polarity]))\n",
    "        row_s = pd.Series(row_p)\n",
    "        row_s.name = i\n",
    "        general_tweets_corpus_train_2017_balanced = general_tweets_corpus_train_2017_balanced.append(row_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P      133\n",
       "NEU    133\n",
       "N      133\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_tweets_corpus_train_2017_balanced.polarity.value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import/read biggest corpus (2012), to concatenate it with the previous one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 values of sentiment: N, P, NONE, NEU\n",
    "xml = objectify.parse(open(corpus_tweets_2012_xml))\n",
    "root = xml.getroot()\n",
    "general_tweets_corpus_train_2012 = pd.DataFrame(columns=('content', 'polarity'))\n",
    "tweets = root.getchildren()\n",
    "for i in range(0, len(tweets)):\n",
    "    tweet = tweets[i]\n",
    "    row = dict(zip(['content', 'polarity'], [tweet.content.text, tweet.sentiments.polarity.value.text]))\n",
    "    row_s = pd.Series(row)\n",
    "    row_s.name = i\n",
    "    general_tweets_corpus_train_2012 = general_tweets_corpus_train_2012.append(row_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P       2884\n",
       "N       2182\n",
       "NONE    1483\n",
       "NEU      670\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_tweets_corpus_train_2012.polarity.value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of tweets to remove\n",
    "positive_to_remove = 2884-670\n",
    "negative_to_remove = 2182-670\n",
    "positive_removed = 0\n",
    "negative_removed = 0\n",
    "\n",
    "# Init balanced version\n",
    "general_tweets_corpus_train_2012_balanced = pd.DataFrame(columns=('content', 'polarity'))\n",
    "\n",
    "# We balance the dataset, to have the same number of positive, negative and neutral polarity\n",
    "for i, row in general_tweets_corpus_train_2012.iterrows():\n",
    "    if(row.polarity) == 'P':\n",
    "        positive_removed = positive_removed + 1\n",
    "        if(positive_removed > positive_to_remove):\n",
    "            row_p = dict(zip(['content', 'polarity'], [row.content, row.polarity]))\n",
    "            row_s = pd.Series(row_p)\n",
    "            row_s.name = i\n",
    "            general_tweets_corpus_train_2012_balanced = general_tweets_corpus_train_2012_balanced.append(row_s)\n",
    "    if(row.polarity) == 'N':\n",
    "        negative_removed = negative_removed + 1\n",
    "        if(negative_removed > negative_to_remove):\n",
    "            row_p = dict(zip(['content', 'polarity'], [row.content, row.polarity]))\n",
    "            row_s = pd.Series(row_p)\n",
    "            row_s.name = i\n",
    "            general_tweets_corpus_train_2012_balanced = general_tweets_corpus_train_2012_balanced.append(row_s)\n",
    "    if(row.polarity) == 'NEU':\n",
    "        row_p = dict(zip(['content', 'polarity'], [row.content, row.polarity]))\n",
    "        row_s = pd.Series(row_p)\n",
    "        row_s.name = i\n",
    "        general_tweets_corpus_train_2012_balanced = general_tweets_corpus_train_2012_balanced.append(row_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P      670\n",
       "NEU    670\n",
       "N      670\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_tweets_corpus_train_2012_balanced.polarity.value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import/read emoji sentiment dataset, to concatenate with the previous ones. Build column `polarity` according to the following criteria:\n",
    "- If sentiment score is between -1 and -0.2, consider it a **negative** sentiment (`N`).\n",
    "- If sentiment score is between -0.2 and 0.2, consider it a **neutral** sentiment (`NEU`).\n",
    "- If sentiment score is between 0.2 and 1, consider it a **positive** sentiment (`P`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# Read emojis CSV\n",
    "emoji_dataset = pd.read_csv(emojis_csv, encoding='utf-8')\n",
    "\n",
    "# Init dataframe to append to corpus\n",
    "emoji_corpus = pd.DataFrame(columns=('content', 'polarity'))\n",
    "\n",
    "# Build column 'polarity\n",
    "emoji_dataset['polarity'] = 'NEU'\n",
    "emoji_dataset['polarity'][emoji_dataset.sentiment < 0] = 'N'\n",
    "emoji_dataset['polarity'][emoji_dataset.sentiment > 0.2] = 'P'\n",
    "\n",
    "for i, row in emoji_dataset.iterrows():\n",
    "    new_row = dict(zip(['content', 'polarity'], [chr(int(row.emoji, 16)), row.polarity]))\n",
    "    row_s = pd.Series(new_row)\n",
    "    row_s.name = i\n",
    "    emoji_corpus = emoji_corpus.append(row_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P      482\n",
       "NEU    170\n",
       "N       99\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_corpus.polarity.value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate general corpus dataset with 2017 one, to have a better result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus = pd.concat([\n",
    "        general_tweets_corpus_train_2012,\n",
    "        general_tweets_corpus_train_2017,\n",
    "        emoji_corpus\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove tweets with polarity 'NONE'\n",
    "tweets_corpus = tweets_corpus.query('polarity != \"NONE\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P      0.406646\n",
       "NEU    0.307911\n",
       "N      0.285443\n",
       "Name: polarity, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.polarity.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import regex tools\n",
    "import re\n",
    "\n",
    "# Build emoji regex\n",
    "emoji_string = '|'.join(emoji_corpus['content'])\n",
    "emoji_regex = re.compile(r'(%s)' % emoji_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>🐐</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6023</th>\n",
       "      <td>Como ir en avión... http://t.co/AZ9z4uFM</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>\"@MartaG_novo: A las 13:00, los portavoces mun...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>Despacio, en paz  http://t.co/AQKTSxq4 via @el...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>☺</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4051</th>\n",
       "      <td>¿Y debería ser  compatible la tarjeta dorada y...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Fin a la impunidad en #Internet http://t.co/j7...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5477</th>\n",
       "      <td>Si Aguirre y Gallardón se ponen de acuerdo en ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>▂</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>🐨</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content polarity\n",
       "621                                                   🐐        P\n",
       "6023           Como ir en avión... http://t.co/AZ9z4uFM     NONE\n",
       "1690  \"@MartaG_novo: A las 13:00, los portavoces mun...     NONE\n",
       "818   Despacio, en paz  http://t.co/AQKTSxq4 via @el...     NONE\n",
       "11                                                    ☺        P\n",
       "4051  ¿Y debería ser  compatible la tarjeta dorada y...        N\n",
       "156   Fin a la impunidad en #Internet http://t.co/j7...        P\n",
       "5477  Si Aguirre y Gallardón se ponen de acuerdo en ...        N\n",
       "563                                                   ▂      NEU\n",
       "373                                                   🐨        P"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus tweets: 8978\n"
     ]
    }
   ],
   "source": [
    "print('Total corpus tweets: %d' % len(tweets_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cleaner import clean_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we clean the train and test data with the previous function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_corpus = clean_tweets(tweets_corpus, 'content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus tweets after cleaning: 7356\n"
     ]
    }
   ],
   "source": [
    "print('Total corpus tweets after cleaning: %d' % len(tweets_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>pero nos hemos desmovilizado, Concha. Nosotro...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5323</th>\n",
       "      <td>Sí. Grabando el pgrama para el invierno más SE...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4168</th>\n",
       "      <td>A las 17.45 viene al estudio de #JELO Alicia S...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>🐻</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>El lunes 26, estreno de El Número Uno vía</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>👸</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5435</th>\n",
       "      <td>\"Batasuna toma el Parlamento Vasco\" via</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>aquí podéis encontrar las fotos de mi segundo ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3956</th>\n",
       "      <td>Detalle inquietante de la conformación Multidi...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5347</th>\n",
       "      <td>A visitar Andiex . Empresa antequerana de vent...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content polarity\n",
       "192    pero nos hemos desmovilizado, Concha. Nosotro...        N\n",
       "5323  Sí. Grabando el pgrama para el invierno más SE...        N\n",
       "4168  A las 17.45 viene al estudio de #JELO Alicia S...        P\n",
       "308                                                  🐻         P\n",
       "5791         El lunes 26, estreno de El Número Uno vía         P\n",
       "192                                                  👸         P\n",
       "5435           \"Batasuna toma el Parlamento Vasco\" via         N\n",
       "2171  aquí podéis encontrar las fotos de mi segundo ...        P\n",
       "3956  Detalle inquietante de la conformación Multidi...      NEU\n",
       "5347  A visitar Andiex . Empresa antequerana de vent...        P"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export corpus tweets as CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_corpus.to_csv(corpus_tweets_csv, encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
