{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet classification\n",
    "\n",
    "File names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_location = './'\n",
    "\n",
    "# To read\n",
    "tweets_raw_file = base_location + 'datasets/train.csv'\n",
    "tweets_run_file = base_location + 'datasets/test_nolabel.csv'\n",
    "corpus_tweets_2012_xml = base_location + 'general-train-tagged-3l.xml'\n",
    "corpus_tweets_2017_xml = base_location + 'intertass-train-tagged.xml'\n",
    "\n",
    "# To generate\n",
    "corpus_tweets_2012_csv = base_location + 'general-train-tagged-3l.csv'\n",
    "corpus_tweets_2017_csv = base_location + 'intertass-train-tagged.csv'\n",
    "corpus_tweets_csv = base_location + 'corpus_tweets.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets: 411\n",
      "Evaluated tweets so far: 177\n"
     ]
    }
   ],
   "source": [
    "tweets_raw = pd.read_csv(tweets_raw_file, encoding='utf-8')\n",
    "tweets_run = pd.read_csv(tweets_run_file, encoding='utf-8')\n",
    "\n",
    "print('Total tweets: %d' % len(tweets_raw))\n",
    "print('Evaluated tweets so far: %d' % len(tweets_run))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build new array of dictionaries with keys `id` (the task ID), `tweet` (the tweet string) and `score` (the tweet evaluation) by joining data from both CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total different tweets evaluated so far: 411\n"
     ]
    }
   ],
   "source": [
    "# Build dictionary of tweets where key is the task__id\n",
    "own_tweets = []\n",
    "tweets_obj = {}\n",
    "for index, row in tweets_raw.iterrows():\n",
    "    own_tweets.append({\n",
    "        'id': row.id,\n",
    "        'tweet': row.text, \n",
    "        'polarity': row.polarity\n",
    "    })\n",
    "\n",
    "print('Total different tweets evaluated so far: %d' % len(own_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging\n",
    "\n",
    "Import libraries to read XML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import objectify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import/read most recent corpus (2017):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 values of sentiment: N, P, NONE, NEU\n",
    "xml = objectify.parse(open(corpus_tweets_2017_xml))\n",
    "root = xml.getroot()\n",
    "general_tweets_corpus_train_2017 = pd.DataFrame(columns=('content', 'polarity'))\n",
    "tweets = root.getchildren()\n",
    "for i in range(0, len(tweets)):\n",
    "    tweet = tweets[i]\n",
    "    row = dict(zip(['content', 'polarity'], [tweet.content.text, tweet.sentiment.polarity.value.text]))\n",
    "    row_s = pd.Series(row)\n",
    "    row_s.name = i\n",
    "    general_tweets_corpus_train_2017 = general_tweets_corpus_train_2017.append(row_s)\n",
    "    \n",
    "general_tweets_corpus_train_2017.to_csv(corpus_tweets_2017_csv, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import/read biggest corpus (2012), to concatenate it with the previous one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 values of sentiment: N, P, NONE, NEU\n",
    "xml = objectify.parse(open(corpus_tweets_2012_xml))\n",
    "root = xml.getroot()\n",
    "general_tweets_corpus_train_2012 = pd.DataFrame(columns=('content', 'polarity'))\n",
    "tweets = root.getchildren()\n",
    "for i in range(0, len(tweets)):\n",
    "    tweet = tweets[i]\n",
    "    row = dict(zip(['content', 'polarity'], [tweet.content.text, tweet.sentiments.polarity.value.text]))\n",
    "    row_s = pd.Series(row)\n",
    "    row_s.name = i\n",
    "    general_tweets_corpus_train_2012 = general_tweets_corpus_train_2012.append(row_s)\n",
    "    \n",
    "general_tweets_corpus_train_2012.to_csv(corpus_tweets_2012_csv, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate general corpus dataset with 2017 one, to have a better result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Ah vale, me suelta la puta subnormal, te estoy...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>#Chac√≥n defiende que las primarias del @PSOE s...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Viernes negro: Aumenta el paro en Noviembre y ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>@PGimenezFuentes @CiudadanosCs paso, paso de t...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>#fb El ministro del Interior anuncia en @OndaC...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165</th>\n",
       "      <td>Montoro cree  q RTVE no tiene q competir con l...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>‚Äú@javiercasqueiro: Aqu√≠ est√° el rosc√≥n http://...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4761</th>\n",
       "      <td>;-)))) RT @soniachaconp: @mariviromero Gracias...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5853</th>\n",
       "      <td>Y si directores generales d la Administraci√≥n ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3632</th>\n",
       "      <td>@sanchez_sonia No te has ido de ah√≠?. Buenos d√≠as</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content polarity\n",
       "62    Ah vale, me suelta la puta subnormal, te estoy...        N\n",
       "1468  #Chac√≥n defiende que las primarias del @PSOE s...        P\n",
       "22    Viernes negro: Aumenta el paro en Noviembre y ...        N\n",
       "500   @PGimenezFuentes @CiudadanosCs paso, paso de t...        N\n",
       "1475  #fb El ministro del Interior anuncia en @OndaC...        P\n",
       "6165  Montoro cree  q RTVE no tiene q competir con l...        N\n",
       "1888  ‚Äú@javiercasqueiro: Aqu√≠ est√° el rosc√≥n http://...        N\n",
       "4761  ;-)))) RT @soniachaconp: @mariviromero Gracias...        P\n",
       "5853  Y si directores generales d la Administraci√≥n ...        N\n",
       "3632  @sanchez_sonia No te has ido de ah√≠?. Buenos d√≠as     NONE"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus = pd.concat([\n",
    "        general_tweets_corpus_train_2012,\n",
    "        general_tweets_corpus_train_2017\n",
    "    ])\n",
    "tweets_corpus.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus tweets: 8227\n"
     ]
    }
   ],
   "source": [
    "print('Total corpus tweets: %d' % len(tweets_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove tweets without polarity (polarity `NONE`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus = tweets_corpus.query('polarity != \"NONE\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove tweets that are only a link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus = tweets_corpus[-tweets_corpus.content.str.contains('^http.*$')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import regex tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we remove links, usernames, newline characters, multiple spaces and emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus_no_links = tweets_corpus\n",
    "\n",
    "# Remove links\n",
    "tweets_corpus_no_links['content'] = tweets_corpus_no_links['content'].map(lambda x: re.sub(re.compile('https?:\\/\\/t\\.co\\/[\\w]{8,8}'), '', x))\n",
    "\n",
    "# Remove usernames\n",
    "tweets_corpus_no_links['content'] = tweets_corpus_no_links['content'].map(lambda x: re.sub(re.compile('@[A-Za-z0-9_]+'), '', x))\n",
    "\n",
    "# Remove newline character\n",
    "tweets_corpus_no_links['content'] = tweets_corpus_no_links['content'].map(lambda x: re.sub(re.compile('[\\n\\r]+'), '', x))\n",
    "\n",
    "# Replace multiple spaces with single one\n",
    "tweets_corpus_no_links['content'] = tweets_corpus_no_links['content'].map(lambda x: re.sub(re.compile('[\\s]+'), ' ', x))\n",
    "\n",
    "# Remove emojis\n",
    "emoji_pattern = re.compile(u'['\n",
    "     u'\\U0001F300-\\U0001F64F'\n",
    "     u'\\U0001F680-\\U0001F6FF'\n",
    "     u'\\u2600-\\u26FF\\u2700-\\u27BF]+', \n",
    "     re.UNICODE)\n",
    "#tweets_corpus_no_links['content'] = tweets_corpus_no_links['content'].map(lambda x: re.sub(emoji_pattern, ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus tweets after cleaning: 6586\n"
     ]
    }
   ],
   "source": [
    "print('Total corpus tweets after cleaning: %d' % len(tweets_corpus_no_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6516</th>\n",
       "      <td>Deseo de mucho √©xito al alcalde de Oropesa. Pa...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>¬°Qu√© pintaza! Tanto la chistorra como el lomo...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>Adi√≥s al maestro de humanidad: v√≠a</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4584</th>\n",
       "      <td>En definitiva, un paso m√°s para la creaci√≥n de...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5739</th>\n",
       "      <td>Las simplezas de</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>Desde luego ‚Äú: Pasado contrapasado no conlleva...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>Un buen botijo hace buen agua. Pero un buen bo...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>La reuni√≥n de la Mesa del Congreso convocada p...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5657</th>\n",
       "      <td>Quiero ser un alcalde para #Andaluc√≠a. Un alca...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>Y perdonad que no me haya hecho fotos con los ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content polarity\n",
       "6516  Deseo de mucho √©xito al alcalde de Oropesa. Pa...        P\n",
       "787    ¬°Qu√© pintaza! Tanto la chistorra como el lomo...        P\n",
       "2227                Adi√≥s al maestro de humanidad: v√≠a         N\n",
       "4584  En definitiva, un paso m√°s para la creaci√≥n de...        P\n",
       "5739                                  Las simplezas de         N\n",
       "2639  Desde luego ‚Äú: Pasado contrapasado no conlleva...        N\n",
       "3140  Un buen botijo hace buen agua. Pero un buen bo...      NEU\n",
       "684   La reuni√≥n de la Mesa del Congreso convocada p...        N\n",
       "5657  Quiero ser un alcalde para #Andaluc√≠a. Un alca...        P\n",
       "1732  Y perdonad que no me haya hecho fotos con los ...        P"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and stemming\n",
    "\n",
    "Download Spanish stopwords in Spanish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jabatrox/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# Download spanish stopwords\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "spanish_stopwords = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get non-words, and extend array of non-words with characters `¬ø` and `¬ø`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "non_words = list(punctuation)\n",
    "\n",
    "# Add spanish punctuation\n",
    "non_words.extend(['¬ø', '¬°'])\n",
    "non_words.extend(map(str,range(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define stemmer and tokenizer, based on previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer       \n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# based on http://www.cs.duke.edu/courses/spring14/compsci290/assignments/lab02.html\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    # remove non letters\n",
    "    text = ''.join([c for c in text if c not in non_words])\n",
    "    # tokenize\n",
    "    tokens =  word_tokenize(text)\n",
    "\n",
    "    # stem\n",
    "    try:\n",
    "        stems = stem_tokens(tokens, stemmer)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(text)\n",
    "        stems = ['']\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>Happy bday happy bday mom! Feliz cumple a la m...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>La mejor forma de garantizar la seguridad de n...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>RT Papel√≥n #ZP entre el chipriota y el irland√©...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>¬øY t√∫ de que trabajas? Yo ayudo a \"perfilar le...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>\" el cambio que proponemos es el cambio tranqu...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>que es un envidiosillo</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5250</th>\n",
       "      <td>El secreto para que una dieta funcione es deci...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>Patxi L√≥pez reclama acercamiento de presos. 20:30</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6721</th>\n",
       "      <td>#Presupuestos Y ahora cuenta Montoro algunas d...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>#cabalgatasevilla llega a Pza.Magdalena.Espect...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content polarity\n",
       "2005  Happy bday happy bday mom! Feliz cumple a la m...        P\n",
       "1290  La mejor forma de garantizar la seguridad de n...        N\n",
       "343   RT Papel√≥n #ZP entre el chipriota y el irland√©...        N\n",
       "689   ¬øY t√∫ de que trabajas? Yo ayudo a \"perfilar le...        N\n",
       "2377  \" el cambio que proponemos es el cambio tranqu...        P\n",
       "923                             que es un envidiosillo         N\n",
       "5250  El secreto para que una dieta funcione es deci...        P\n",
       "2022  Patxi L√≥pez reclama acercamiento de presos. 20:30        N\n",
       "6721  #Presupuestos Y ahora cuenta Montoro algunas d...        N\n",
       "1835  #cabalgatasevilla llega a Pza.Magdalena.Espect...        P"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert from strings to numerics the polarity values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jabatrox/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/jabatrox/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " 1    0.483602\n",
       "-1    0.394777\n",
       " 0    0.121622\n",
       "Name: polarity_bin, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus_no_links['polarity_bin'] = 0\n",
    "tweets_corpus_no_links.polarity_bin[tweets_corpus_no_links.polarity.isin(['P'])] = 1\n",
    "tweets_corpus_no_links.polarity_bin[tweets_corpus_no_links.polarity.isin(['N'])] = -1\n",
    "tweets_corpus_no_links.polarity_bin.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use SVC model with optimization via GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jabatrox/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words=['de', 'la'...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'vect__max_df': (0.5, 1.9), 'vect__min_df': (10, 20, 50), 'vect__max_features': (500, 1000), 'vect__ngram_range': ((1, 1), (1, 2)), 'rfc__n_estimators': [50, 100, 200], 'rfc__min_samples_split': [2, 3, 4, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "vectorizer = CountVectorizer(\n",
    "                analyzer = 'word',\n",
    "                tokenizer = tokenize,\n",
    "                lowercase = True,\n",
    "                stop_words = spanish_stopwords)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('rfc', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 1.9),\n",
    "    'vect__min_df': (10, 20,50),\n",
    "    'vect__max_features': (500, 1000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'rfc__n_estimators':[50, 100, 200],\n",
    "    'rfc__min_samples_split':[2, 3, 4, 5, 10]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1)\n",
    "grid_search.fit(tweets_corpus_no_links.content, tweets_corpus_no_links.polarity_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As long as we don't have binary classification, we must binarize the polarity and use a multiclass learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.preprocessing import label_binarize\\ntweets_corpus_no_links.polarity_bin = label_binarize(tweets_corpus_no_links.polarity_bin, classes=[-1, 0, 1])'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.preprocessing import label_binarize\n",
    "tweets_corpus_no_links.polarity_bin = label_binarize(tweets_corpus_no_links.polarity_bin, classes=[-1, 0, 1])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"params = {\\n    'vect__max_df': (0.5, 1.9),\\n    'vect__min_df': (10, 20,50),\\n    'vect__max_features': (500, 1000),\\n    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\\n    'cls__estimator__C': (0.2, 0.5, 0.7),\\n    'cls__estimator__loss': ('hinge', 'squared_hinge'),\\n    'cls__estimator__max_iter': (500, 1000)\\n      }\\ngs = GridSearchCV(pipeline, params, n_jobs=-1, cv=5, scoring='roc_auc')\\ngs.fit(tweets_corpus_no_links.content, tweets_corpus_no_links.polarity_bin)\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''params = {\n",
    "    'vect__max_df': (0.5, 1.9),\n",
    "    'vect__min_df': (10, 20,50),\n",
    "    'vect__max_features': (500, 1000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'cls__estimator__C': (0.2, 0.5, 0.7),\n",
    "    'cls__estimator__loss': ('hinge', 'squared_hinge'),\n",
    "    'cls__estimator__max_iter': (500, 1000)\n",
    "      }\n",
    "gs = GridSearchCV(pipeline, params, n_jobs=-1, cv=5, scoring='roc_auc')\n",
    "gs.fit(tweets_corpus_no_links.content, tweets_corpus_no_links.polarity_bin)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs.best_params_'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''gs.best_params_'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain that the best parameters are:\n",
    "\n",
    "{'cls__estimator__C': 0.2,\n",
    "\n",
    " 'cls__estimator__loss': 'hinge',\n",
    " \n",
    " 'cls__estimator__max_iter': 1000,\n",
    " \n",
    " 'vect__max_df': 1.9,\n",
    " \n",
    " 'vect__max_features': 1000,\n",
    " \n",
    " 'vect__min_df': 10,\n",
    " \n",
    " 'vect__ngram_range': (1, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.externals import joblib\\njoblib.dump(gs, 'grid_search.pkl')\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.externals import joblib\n",
    "joblib.dump(gs, 'grid_search.pkl')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "GridSearchCV(cv=None, error_score='raise',\n",
    "       estimator=Pipeline(memory=None,\n",
    "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
    "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
    "        ngram_range=(1, 1), preprocessor=None,\n",
    "        stop_words=['de', 'la'...n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False))]),\n",
    "       fit_params=None, iid=True, n_jobs=-1,\n",
    "       param_grid={'vect__max_df': (0.5, 1.9), 'vect__min_df': (10, 20, 50), 'vect__max_features': (500, 1000), 'vect__ngram_range': ((1, 1), (1, 2)), 'rfc__n_estimators': [50, 100, 200], 'rfc__min_samples_split': [2, 3, 4, 5, 10]},\n",
    "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
    "       scoring=None, verbose=0)\n",
    "'''\n",
    "\n",
    "\n",
    "model = LinearSVC(\n",
    "    C=.2, \n",
    "    loss='hinge', \n",
    "    max_iter=1000, \n",
    "    random_state=None, \n",
    "    penalty='l2'\n",
    ")\n",
    "\n",
    "# Define vectorizer with the previously created tokenizer and stopwords array\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    tokenizer = tokenize,\n",
    "    lowercase = True,\n",
    "    stop_words = spanish_stopwords,\n",
    "    min_df = 10,\n",
    "    max_df = 1.9,\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=1000\n",
    ")\n",
    "\n",
    "corpus_data_features = vectorizer.fit_transform(tweets_corpus_no_links.content)\n",
    "corpus_data_features_nd = corpus_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=tweets_corpus_no_links.polarity_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"scores = cross_val_score(\\n    model,\\n    corpus_data_features_nd[0:len(tweets_corpus_no_links)],\\n    y=tweets_corpus_no_links.polarity_bin,\\n    scoring='roc_auc',\\n    cv=5\\n    )\\n\\nscores.mean()\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''scores = cross_val_score(\n",
    "    model,\n",
    "    corpus_data_features_nd[0:len(tweets_corpus_no_links)],\n",
    "    y=tweets_corpus_no_links.polarity_bin,\n",
    "    scoring='roc_auc',\n",
    "    cv=5\n",
    "    )\n",
    "\n",
    "scores.mean()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polarity Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets: 177\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>42d8ce05</td>\n",
       "      <td>@maldiniplus Como dijo Draxler, el planteamien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>f067a08b</td>\n",
       "      <td>@moscu_toronto Pues cuando era peque√±ito era d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>65da3719</td>\n",
       "      <td>@LlunaCatalana3 tv3 te els drets de la champio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>e71a115b</td>\n",
       "      <td>@EASPORTSEsp Griezmann no ser√° por el partido ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2ddfa69e</td>\n",
       "      <td>@AlejandroNY75 @2010MisterChip Y peor. Elogia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>12d82762</td>\n",
       "      <td>EL DIRECTO EN EL QUE DjMaRiiO US√ì LA CAMISETA ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ebf7bff7</td>\n",
       "      <td>Andr√© Gomes no est√° dando el nivel pero los ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5a533794</td>\n",
       "      <td>¬°EL INICIO DE UNA LEYENDA! üî¥üîµ\\n\\n¬øQu√© momento ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>41de1a3a</td>\n",
       "      <td>La #EuropeaLeague el #Atl√©tico se la tiene que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6eb6eb37</td>\n",
       "      <td>Neymar se fue al PSG en busca de ‚Äút√≠tulos‚Äù, si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text\n",
       "156  42d8ce05  @maldiniplus Como dijo Draxler, el planteamien...\n",
       "58   f067a08b  @moscu_toronto Pues cuando era peque√±ito era d...\n",
       "137  65da3719  @LlunaCatalana3 tv3 te els drets de la champio...\n",
       "168  e71a115b  @EASPORTSEsp Griezmann no ser√° por el partido ...\n",
       "71   2ddfa69e  @AlejandroNY75 @2010MisterChip Y peor. Elogia ...\n",
       "74   12d82762  EL DIRECTO EN EL QUE DjMaRiiO US√ì LA CAMISETA ...\n",
       "6    ebf7bff7  Andr√© Gomes no est√° dando el nivel pero los ab...\n",
       "42   5a533794  ¬°EL INICIO DE UNA LEYENDA! üî¥üîµ\\n\\n¬øQu√© momento ...\n",
       "45   41de1a3a  La #EuropeaLeague el #Atl√©tico se la tiene que...\n",
       "77   6eb6eb37  Neymar se fue al PSG en busca de ‚Äút√≠tulos‚Äù, si..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_no_label = pd.read_csv(tweets_run_file, encoding='utf-8')\n",
    "print('Number of tweets: %d' % tweets_no_label.shape[0])\n",
    "tweets_no_label.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do some cleansing of the data, erasing again the links, usernames, newline characters, multiple spaces and emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove links\n",
    "tweets_no_label['text'] = tweets_no_label['text'].map(lambda x: re.sub(re.compile('https?:\\/\\/t\\.co\\/[\\w]{8,8}'), '', x))\n",
    "\n",
    "# Remove usernames\n",
    "tweets_no_label['text'] = tweets_no_label['text'].map(lambda x: re.sub(re.compile('@[A-Za-z0-9_]+'), '', x))\n",
    "\n",
    "# Remove newline character\n",
    "tweets_no_label['text'] = tweets_no_label['text'].map(lambda x: re.sub(re.compile('[\\n\\r]+'), '', x))\n",
    "\n",
    "# Replace multiple spaces with single one\n",
    "tweets_no_label['text'] = tweets_no_label['text'].map(lambda x: re.sub(re.compile('[\\s]+'), ' ', x))\n",
    "\n",
    "# Remove emojis\n",
    "emoji_pattern = re.compile(u'['\n",
    "     u'\\U0001F300-\\U0001F64F'\n",
    "     u'\\U0001F680-\\U0001F6FF'\n",
    "     u'\\u2600-\\u26FF\\u2700-\\u27BF]+', \n",
    "     re.UNICODE)\n",
    "#tweets_no_label['text'] = tweets_no_label['text'].map(lambda x: re.sub(emoji_pattern, ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>5b4878db</td>\n",
       "      <td>¬øAquellos casi atracos al Bar√ßa?, no se que d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>cee9b0a5</td>\n",
       "      <td>Que solo soy feliz con el atleti de madrid!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>be694b7a</td>\n",
       "      <td>Le tienen tanto odio, que hasta le critican po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>884da2b9</td>\n",
       "      <td>Resulta que el partido lo perdi√≥ el PSG por l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>b492b317</td>\n",
       "      <td>La 'rajada' de un ex objetivo del Bar√ßa sobre ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>484c36cf</td>\n",
       "      <td>La victoria de ayer a la prensa tampoco le val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a122a538</td>\n",
       "      <td>Un jugador brasile√±o de 21 a√±os muy bueno q j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>97e7b943</td>\n",
       "      <td>Eso decidselo a Marca que cada d√≠a dan m√°s ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79cdded5</td>\n",
       "      <td>FELICIDADES ¬°¬° FRANCISCO¬°¬°üéÇüéÇüéÇüéÇüéÇüéÇüéÇüéÇüéÇüéÇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2687f611</td>\n",
       "      <td>El atleti no juega contra el PSG x q le elimi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text\n",
       "91   5b4878db   ¬øAquellos casi atracos al Bar√ßa?, no se que d...\n",
       "73   cee9b0a5      Que solo soy feliz con el atleti de madrid!!!\n",
       "97   be694b7a  Le tienen tanto odio, que hasta le critican po...\n",
       "105  884da2b9   Resulta que el partido lo perdi√≥ el PSG por l...\n",
       "68   b492b317  La 'rajada' de un ex objetivo del Bar√ßa sobre ...\n",
       "47   484c36cf  La victoria de ayer a la prensa tampoco le val...\n",
       "10   a122a538   Un jugador brasile√±o de 21 a√±os muy bueno q j...\n",
       "158  97e7b943   Eso decidselo a Marca que cada d√≠a dan m√°s ve...\n",
       "1    79cdded5               FELICIDADES ¬°¬° FRANCISCO¬°¬°üéÇüéÇüéÇüéÇüéÇüéÇüéÇüéÇüéÇüéÇ\n",
       "89   2687f611   El atleti no juega contra el PSG x q le elimi..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_no_label.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Language detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the fact that some tweets are in catalan, for language detection purposes we are only going to process about the ones in spanish for sentiment purposes.\n",
    "\n",
    "We use three different libraries for language detection and keep those tweets on which at least two of these libraries agree on the language being Spanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langid\n",
    "from langdetect import detect\n",
    "import textblob\n",
    "\n",
    "def langid_safe(tweet):\n",
    "    try:\n",
    "        return langid.classify(tweet)[0]\n",
    "    except Exception as e:\n",
    "        pass\n",
    "        \n",
    "def langdetect_safe(tweet):\n",
    "    try:\n",
    "        return detect(tweet)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "def textblob_safe(tweet):\n",
    "    try:\n",
    "        return textblob.TextBlob(tweet).detect_language()\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 3 new columns specifying the detected language of the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_no_label['lang_langid'] = tweets_no_label.text.apply(langid_safe)\n",
    "tweets_no_label['lang_langdetect'] = tweets_no_label.text.apply(langdetect_safe)\n",
    "tweets_no_label['lang_textblob'] = tweets_no_label.text.apply(textblob_safe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save as CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_no_label.to_csv('tweets_parsed.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the tweets in Spanish as follows:\n",
    "- If the language detected is Spanish by at least 2 libraries, leave.\n",
    "- If the language detected is Spanish in at least 1 library, print and append to the dataset manually.\n",
    "- If none of the languages detected is Spanish, remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets in Spanish: 150\n",
      "Tweets whose language is not clear: 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>lang_langid</th>\n",
       "      <th>lang_langdetect</th>\n",
       "      <th>lang_textblob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79cdded5</td>\n",
       "      <td>FELICIDADES ¬°¬° FRANCISCO¬°¬°üéÇüéÇüéÇüéÇüéÇüéÇüéÇüéÇüéÇüéÇ</td>\n",
       "      <td>zh</td>\n",
       "      <td>de</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26fe7471</td>\n",
       "      <td>Dedicado para: 0F</td>\n",
       "      <td>pt</td>\n",
       "      <td>pt</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cd0d8bcb</td>\n",
       "      <td>DRAXLER EXPLOTA vs el PSG | BALOTELLI ‚Äòmanda C...</td>\n",
       "      <td>es</td>\n",
       "      <td>ca</td>\n",
       "      <td>ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>97af720a</td>\n",
       "      <td>Para el que quiera ver el Bar√ßa hoy, es a las ...</td>\n",
       "      <td>ca</td>\n",
       "      <td>ca</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>09c0f4cc</td>\n",
       "      <td>El Bar√ßa Lassa deja casi vac√≠a la enfermer√≠a 9...</td>\n",
       "      <td>an</td>\n",
       "      <td>ca</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5a533794</td>\n",
       "      <td>¬°EL INICIO DE UNA LEYENDA! üî¥üîµ¬øQu√© momento recu...</td>\n",
       "      <td>pt</td>\n",
       "      <td>pt</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>9046f222</td>\n",
       "      <td>ULTIMA HORA: EL PRESIDENTE DEL PSG LE OFRECE A...</td>\n",
       "      <td>tr</td>\n",
       "      <td>en</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5df2d140</td>\n",
       "      <td>Me ha gustado un v√≠deo de (tG - EL DIRECTO EN ...</td>\n",
       "      <td>gl</td>\n",
       "      <td>pt</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>c5343fa0</td>\n",
       "      <td>Y al Atleti que miura la va a tocar ahora en ...</td>\n",
       "      <td>ca</td>\n",
       "      <td>ca</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>12d82762</td>\n",
       "      <td>EL DIRECTO EN EL QUE DjMaRiiO US√ì LA CAMISETA ...</td>\n",
       "      <td>tr</td>\n",
       "      <td>pt</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>dcc02374</td>\n",
       "      <td>No es muy dif√≠cil Bar√ßa va Madrid</td>\n",
       "      <td>ca</td>\n",
       "      <td>ca</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>8f9d73cf</td>\n",
       "      <td>Cualquiera que no estuvieran ni Bar√ßa ni Madrid.</td>\n",
       "      <td>ca</td>\n",
       "      <td>ca</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6f30beca</td>\n",
       "      <td>CON LA MIRA PUESTA EN MALAGA.SE VIENE PARTIDO ...</td>\n",
       "      <td>ga</td>\n",
       "      <td>en</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>9cd8b232</td>\n",
       "      <td>LO QUE PASA ES QUE EL QUE HABLA PAJA SOY VOH ...</td>\n",
       "      <td>fi</td>\n",
       "      <td>pt</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>3c78bdb5</td>\n",
       "      <td>Sport, el Bar√ßa descart√≥ en el pasado a Lucas ...</td>\n",
       "      <td>ca</td>\n",
       "      <td>ca</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>3beadb3a</td>\n",
       "      <td>üìåInforma : ha fet cursa cont√≠nua avui a la Ciu...</td>\n",
       "      <td>es</td>\n",
       "      <td>ca</td>\n",
       "      <td>ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>c8cda282</td>\n",
       "      <td>Igual que los del Bar√ßa hacerse del PSG.</td>\n",
       "      <td>oc</td>\n",
       "      <td>ca</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>fce60e59</td>\n",
       "      <td>Iniesta inicia su plan en la Ciutat Esportiva ...</td>\n",
       "      <td>es</td>\n",
       "      <td>ca</td>\n",
       "      <td>ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>7bd204cc</td>\n",
       "      <td>Yo no me abono</td>\n",
       "      <td>pt</td>\n",
       "      <td>it</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text lang_langid  \\\n",
       "1    79cdded5               FELICIDADES ¬°¬° FRANCISCO¬°¬°üéÇüéÇüéÇüéÇüéÇüéÇüéÇüéÇüéÇüéÇ          zh   \n",
       "2    26fe7471                                  Dedicado para: 0F          pt   \n",
       "8    cd0d8bcb  DRAXLER EXPLOTA vs el PSG | BALOTELLI ‚Äòmanda C...          es   \n",
       "17   97af720a  Para el que quiera ver el Bar√ßa hoy, es a las ...          ca   \n",
       "40   09c0f4cc  El Bar√ßa Lassa deja casi vac√≠a la enfermer√≠a 9...          an   \n",
       "42   5a533794  ¬°EL INICIO DE UNA LEYENDA! üî¥üîµ¬øQu√© momento recu...          pt   \n",
       "55   9046f222  ULTIMA HORA: EL PRESIDENTE DEL PSG LE OFRECE A...          tr   \n",
       "56   5df2d140  Me ha gustado un v√≠deo de (tG - EL DIRECTO EN ...          gl   \n",
       "72   c5343fa0   Y al Atleti que miura la va a tocar ahora en ...          ca   \n",
       "74   12d82762  EL DIRECTO EN EL QUE DjMaRiiO US√ì LA CAMISETA ...          tr   \n",
       "76   dcc02374                  No es muy dif√≠cil Bar√ßa va Madrid          ca   \n",
       "96   8f9d73cf   Cualquiera que no estuvieran ni Bar√ßa ni Madrid.          ca   \n",
       "112  6f30beca  CON LA MIRA PUESTA EN MALAGA.SE VIENE PARTIDO ...          ga   \n",
       "124  9cd8b232   LO QUE PASA ES QUE EL QUE HABLA PAJA SOY VOH ...          fi   \n",
       "125  3c78bdb5  Sport, el Bar√ßa descart√≥ en el pasado a Lucas ...          ca   \n",
       "150  3beadb3a  üìåInforma : ha fet cursa cont√≠nua avui a la Ciu...          es   \n",
       "152  c8cda282           Igual que los del Bar√ßa hacerse del PSG.          oc   \n",
       "166  fce60e59  Iniesta inicia su plan en la Ciutat Esportiva ...          es   \n",
       "170  7bd204cc                                     Yo no me abono          pt   \n",
       "\n",
       "    lang_langdetect lang_textblob  \n",
       "1                de            es  \n",
       "2                pt            es  \n",
       "8                ca            ca  \n",
       "17               ca            es  \n",
       "40               ca            es  \n",
       "42               pt            es  \n",
       "55               en            es  \n",
       "56               pt            es  \n",
       "72               ca            es  \n",
       "74               pt            es  \n",
       "76               ca            es  \n",
       "96               ca            es  \n",
       "112              en            es  \n",
       "124              pt            es  \n",
       "125              ca            es  \n",
       "150              ca            ca  \n",
       "152              ca            es  \n",
       "166              ca            ca  \n",
       "170              it            es  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leave tweets whose detected language is Spanish (majority):\n",
    "spanish_query = ''' (lang_langdetect == 'es' and lang_langid == 'es') or (lang_langdetect == 'es' and lang_textblob == 'es') or (lang_textblob == 'es' and lang_langid == 'es') '''\n",
    "tweets_spanish = tweets_no_label.query(spanish_query)\n",
    "\n",
    "print('Tweets in Spanish: %d' % tweets_spanish.shape[0])\n",
    "\n",
    "# Print tweets in doubtful language:\n",
    "nonspanish_query = ''' ((lang_langdetect != 'es' and lang_langid != 'es') or (lang_langdetect != 'es' and lang_textblob != 'es') or (lang_textblob != 'es' and lang_langid != 'es')) and (lang_textblob == 'es' or lang_langid == 'es' or lang_langdetect == 'es') '''\n",
    "tweets_doubtful = tweets_no_label.query(nonspanish_query)\n",
    "\n",
    "print('Tweets whose language is not clear: %d' % tweets_doubtful.shape[0])\n",
    "\n",
    "tweets_doubtful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets in Spanish: 169\n"
     ]
    }
   ],
   "source": [
    "# Append rest of the tweets in Spanish manually\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '79cdded5' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '26fe7471' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == 'cd0d8bcb' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '97af720a' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '09c0f4cc' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '5a533794' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '9046f222' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '5df2d140' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == 'c5343fa0' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '12d82762' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == 'dcc02374' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '8f9d73cf' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '6f30beca' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '9cd8b232' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '3c78bdb5' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '3beadb3a' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == 'c8cda282' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == 'fce60e59' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '7bd204cc' ''')])\n",
    "\n",
    "print('Tweets in Spanish: %d' % tweets_spanish.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(\n",
    "            analyzer = 'word',\n",
    "            tokenizer = tokenize,\n",
    "            lowercase = True,\n",
    "            stop_words = spanish_stopwords,\n",
    "            min_df = 10,\n",
    "            max_df = 1.9,\n",
    "            ngram_range=(1, 1),\n",
    "            max_features=1000\n",
    "            )),\n",
    "    ('cls', OneVsRestClassifier(LinearSVC(C=.2, loss='hinge',max_iter=1000,multi_class='ovr',\n",
    "             random_state=None,\n",
    "             penalty='l2',\n",
    "             ))),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(tweets_corpus_no_links.content, tweets_corpus_no_links.polarity_bin)\n",
    "tweets_no_label['polarity'] = pipeline.predict(tweets_no_label.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Como har√° Griezmann para jugar en Madrid, Bar√ß...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>El Barca aparte de ganar eso ha dominado el f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dedicado para: 0F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Seguro, el Madrid tiene mejor plantilla y da ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>No es muy dif√≠cil Bar√ßa va Madrid</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>M√°s miedo al Bar√ßa que al PSG? Has mencionado ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>tv3 te els drets de la champions, per√≤, no de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vengo 2/2 con los clasificados a Cuartos de Ch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>ESTA TARDE a las 18:45 se juega la SUPERCOPA D...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Creo q ustedes son del Madrid y quieren sacar...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Incomparecencia ayer del PSG. Alguien sabe si...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Hace 17 a√±os, Messi por primera vez se puso la...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Really ? El Espanyol nos gan√≥. üôÑüôÑEste a√±o lo ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Vaya cabezazo del ni√±o. Me record√≥ al de la f...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>¬°EL INICIO DE UNA LEYENDA! üî¥üîµ¬øQu√© momento recu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>OJITO al EJERCICIO de un ni√±o de SEGUNDO de PR...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>A ver si encontr√°is alg√∫n tweet as√≠ a favor de...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Le tienen tanto odio, que hasta le critican po...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Madrid: Cuatro manifestaciones por el 8-M... y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>El que tir√≥ la liga en septiembre el a√±o pasa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Vaya, no nos lo esper√°bamos...; Es curioso com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Para el que quiera ver el Bar√ßa hoy, es a las ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Yo no me abono</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Andr√© Gomes no est√° dando el nivel pero los ab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>No est√°n trabajando en el juego, est√°n cosien...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Jajajajaj puto Mario, pero Sim√≥n, la √∫ltima v...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Md</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>lo terrible es que la afici√≥n del lo tolere, ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MESSI tira del carro del Bar√ßa y cuando se va...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Cuando el PSG permiti√≥ entrar a sus ultras jus...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  polarity\n",
       "12   Como har√° Griezmann para jugar en Madrid, Bar√ß...         1\n",
       "3     El Barca aparte de ganar eso ha dominado el f...         1\n",
       "2                                    Dedicado para: 0F         1\n",
       "23    Seguro, el Madrid tiene mejor plantilla y da ...        -1\n",
       "76                   No es muy dif√≠cil Bar√ßa va Madrid        -1\n",
       "106  M√°s miedo al Bar√ßa que al PSG? Has mencionado ...         1\n",
       "137   tv3 te els drets de la champions, per√≤, no de...         1\n",
       "4    Vengo 2/2 con los clasificados a Cuartos de Ch...         1\n",
       "82   ESTA TARDE a las 18:45 se juega la SUPERCOPA D...         1\n",
       "120   Creo q ustedes son del Madrid y quieren sacar...        -1\n",
       "127   Incomparecencia ayer del PSG. Alguien sabe si...         1\n",
       "174  Hace 17 a√±os, Messi por primera vez se puso la...         1\n",
       "108   Really ? El Espanyol nos gan√≥. üôÑüôÑEste a√±o lo ...        -1\n",
       "114   Vaya cabezazo del ni√±o. Me record√≥ al de la f...        -1\n",
       "42   ¬°EL INICIO DE UNA LEYENDA! üî¥üîµ¬øQu√© momento recu...         1\n",
       "147  OJITO al EJERCICIO de un ni√±o de SEGUNDO de PR...         1\n",
       "44   A ver si encontr√°is alg√∫n tweet as√≠ a favor de...        -1\n",
       "97   Le tienen tanto odio, que hasta le critican po...        -1\n",
       "81   Madrid: Cuatro manifestaciones por el 8-M... y...         1\n",
       "57    El que tir√≥ la liga en septiembre el a√±o pasa...         1\n",
       "131  Vaya, no nos lo esper√°bamos...; Es curioso com...         1\n",
       "17   Para el que quiera ver el Bar√ßa hoy, es a las ...         1\n",
       "170                                     Yo no me abono         1\n",
       "6    Andr√© Gomes no est√° dando el nivel pero los ab...         1\n",
       "113   No est√°n trabajando en el juego, est√°n cosien...        -1\n",
       "95    Jajajajaj puto Mario, pero Sim√≥n, la √∫ltima v...        -1\n",
       "161                                                 Md         1\n",
       "162   lo terrible es que la afici√≥n del lo tolere, ...        -1\n",
       "11    MESSI tira del carro del Bar√ßa y cuando se va...        -1\n",
       "102  Cuando el PSG permiti√≥ entrar a sus ultras jus...        -1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_no_label[['text', 'polarity']].sample(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-convert polarity to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jabatrox/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/jabatrox/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Los parisinos no lo ver√°n este a√±o la famosa C...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Tienes raz√≥n.üëç</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>No soy del Atleti pero me da pena lo que han e...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Lo q no comprendo es por q no salen comparand...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>¬øAquellos casi atracos al Bar√ßa?, no se que d...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Arthur pr√°cticamente hecho, todo est√° firmado ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Cuenta la Leyenda que Todo comenz√≥ hace 17 A√±o...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Este es nivel que tiene la gente. El Madrid nu...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Pobre Catal√°n!! Eres uno de esos del lazo Ama...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Hoy es el cumplea√±os de Francisco Herv√°s Tirad...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Un jugador brasile√±o de 21 a√±os muy bueno q j...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>LO QUE PASA ES QUE EL QUE HABLA PAJA SOY VOH ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>En esta temporada, City Vs Bar√ßa w5</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Vaya, no nos lo esper√°bamos...; Es curioso com...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>anyone in a match against barca</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>(Marca) Unos 1.300 efectivos velar√°n por la se...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Yo no me abono</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>En dias como hoy te das cuenta porque el R. M...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Y al Atleti que miura la va a tocar ahora en ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>F√©lix Brych ayer en el partido de champions #P...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Hace 17 a√±os, Messi por primera vez se puso la...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>¬øEquipo de f√∫tbol favorito? ‚Äî No me gusta el f...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>VRSALJKOüéô: ‚ÄúNo me quej√© a nadie. Soy un profes...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DRAXLER EXPLOTA vs el PSG | BALOTELLI ‚Äòmanda C...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>¬°EL D√çA QUE EL FUTBOL CAMBI√ì! üòçüòçüòçüòçHace 17 a√±os...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Que noooo, as√≠ nos saca unas risas üòÖüòÖüòÖ</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>los que se clasifiquen ya son los mejores, Ba...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>No es muy dif√≠cil Bar√ßa va Madrid</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>4I</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>No est√°n trabajando en el juego, est√°n cosien...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text polarity_bin\n",
       "159  Los parisinos no lo ver√°n este a√±o la famosa C...     Negative\n",
       "48                                      Tienes raz√≥n.üëç     Negative\n",
       "87   No soy del Atleti pero me da pena lo que han e...     Negative\n",
       "128   Lo q no comprendo es por q no salen comparand...     Negative\n",
       "91    ¬øAquellos casi atracos al Bar√ßa?, no se que d...     Negative\n",
       "139  Arthur pr√°cticamente hecho, todo est√° firmado ...     Negative\n",
       "53   Cuenta la Leyenda que Todo comenz√≥ hace 17 A√±o...     Positive\n",
       "111  Este es nivel que tiene la gente. El Madrid nu...     Negative\n",
       "25    Pobre Catal√°n!! Eres uno de esos del lazo Ama...     Negative\n",
       "104  Hoy es el cumplea√±os de Francisco Herv√°s Tirad...     Positive\n",
       "10    Un jugador brasile√±o de 21 a√±os muy bueno q j...     Positive\n",
       "124   LO QUE PASA ES QUE EL QUE HABLA PAJA SOY VOH ...     Negative\n",
       "130                En esta temporada, City Vs Bar√ßa w5     Positive\n",
       "131  Vaya, no nos lo esper√°bamos...; Es curioso com...     Positive\n",
       "61                     anyone in a match against barca     Positive\n",
       "39   (Marca) Unos 1.300 efectivos velar√°n por la se...     Positive\n",
       "170                                     Yo no me abono     Positive\n",
       "135   En dias como hoy te das cuenta porque el R. M...     Negative\n",
       "72    Y al Atleti que miura la va a tocar ahora en ...     Positive\n",
       "133  F√©lix Brych ayer en el partido de champions #P...     Positive\n",
       "171  Hace 17 a√±os, Messi por primera vez se puso la...     Positive\n",
       "119  ¬øEquipo de f√∫tbol favorito? ‚Äî No me gusta el f...     Positive\n",
       "30   VRSALJKOüéô: ‚ÄúNo me quej√© a nadie. Soy un profes...     Positive\n",
       "8    DRAXLER EXPLOTA vs el PSG | BALOTELLI ‚Äòmanda C...     Negative\n",
       "14   ¬°EL D√çA QUE EL FUTBOL CAMBI√ì! üòçüòçüòçüòçHace 17 a√±os...     Positive\n",
       "92              Que noooo, as√≠ nos saca unas risas üòÖüòÖüòÖ     Positive\n",
       "163   los que se clasifiquen ya son los mejores, Ba...     Positive\n",
       "76                   No es muy dif√≠cil Bar√ßa va Madrid     Negative\n",
       "164                                                 4I     Positive\n",
       "113   No est√°n trabajando en el juego, est√°n cosien...     Negative"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets_no_label.copy()\n",
    "tweets['polarity_bin'] = 'Neutral'\n",
    "tweets.polarity_bin[tweets.polarity.isin([1])] = 'Positive'\n",
    "tweets.polarity_bin[tweets.polarity.isin([-1])] = 'Negative'\n",
    "tweets.polarity_bin.value_counts(normalize=True)\n",
    "tweets[['text', 'polarity_bin']].sample(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove aux. columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.drop(['lang_langid', 'lang_langdetect','lang_textblob','polarity'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5d65492b</td>\n",
       "      <td>#BolitaPorfavorINFORMA: üìªüíª‚öΩ Futbol Internacion...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>737f222e</td>\n",
       "      <td>Jajajajaj puto Mario, pero Sim√≥n, la √∫ltima v...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>8675ca7f</td>\n",
       "      <td>Que noooo, as√≠ nos saca unas risas üòÖüòÖüòÖ</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>97af720a</td>\n",
       "      <td>Para el que quiera ver el Bar√ßa hoy, es a las ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>781bcd66</td>\n",
       "      <td>Hace 17 a√±os, #Messi inici√≥ su camino con el 4...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>c5343fa0</td>\n",
       "      <td>Y al Atleti que miura la va a tocar ahora en ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>6d1bd293</td>\n",
       "      <td>Yo soy del Bar√ßa, hinchaba por Neymar</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>e859476c</td>\n",
       "      <td>‚ÄúEl fracaso, como la tristeza, es corrosivo cu...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>8d4d51db</td>\n",
       "      <td>Grand√≠simo. Y esto nunca lo comprender√° un t√≠o...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1e08c5da</td>\n",
       "      <td>Soy 100% fans del Bar√ßa pero no caigo en eso....</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text polarity_bin\n",
       "60   5d65492b  #BolitaPorfavorINFORMA: üìªüíª‚öΩ Futbol Internacion...     Positive\n",
       "95   737f222e   Jajajajaj puto Mario, pero Sim√≥n, la √∫ltima v...     Negative\n",
       "92   8675ca7f             Que noooo, as√≠ nos saca unas risas üòÖüòÖüòÖ     Positive\n",
       "17   97af720a  Para el que quiera ver el Bar√ßa hoy, es a las ...     Positive\n",
       "85   781bcd66  Hace 17 a√±os, #Messi inici√≥ su camino con el 4...     Positive\n",
       "72   c5343fa0   Y al Atleti que miura la va a tocar ahora en ...     Positive\n",
       "109  6d1bd293              Yo soy del Bar√ßa, hinchaba por Neymar     Positive\n",
       "64   e859476c  ‚ÄúEl fracaso, como la tristeza, es corrosivo cu...     Positive\n",
       "84   8d4d51db  Grand√≠simo. Y esto nunca lo comprender√° un t√≠o...     Negative\n",
       "110  1e08c5da   Soy 100% fans del Bar√ßa pero no caigo en eso....     Positive"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename column `polarity_bin` to `polarity`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.rename(columns={'polarity_bin': 'polarity'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export tweets as CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[['id', 'polarity']].to_csv('tweets_polarity_bin.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
