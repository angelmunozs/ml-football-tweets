{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet classification\n",
    "\n",
    "File names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_location = './'\n",
    "\n",
    "# To read\n",
    "tweets_raw_file = base_location + 'datasets/train.csv'\n",
    "tweets_run_file = base_location + 'datasets/test_nolabel.csv'\n",
    "corpus_tweets_2012_xml = base_location + 'general-train-tagged-3l.xml'\n",
    "corpus_tweets_2017_xml = base_location + 'intertass-train-tagged.xml'\n",
    "\n",
    "# To generate\n",
    "corpus_tweets_2012_csv = base_location + 'general-train-tagged-3l.csv'\n",
    "corpus_tweets_2017_csv = base_location + 'intertass-train-tagged.csv'\n",
    "corpus_tweets_csv = base_location + 'corpus_tweets.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets: 411\n",
      "Evaluated tweets so far: 177\n"
     ]
    }
   ],
   "source": [
    "tweets_raw = pd.read_csv(tweets_raw_file, encoding='utf-8')\n",
    "tweets_run = pd.read_csv(tweets_run_file, encoding='utf-8')\n",
    "\n",
    "print('Total tweets: %d' % len(tweets_raw))\n",
    "print('Evaluated tweets so far: %d' % len(tweets_run))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build new array of dictionaries with keys `id` (the task ID), `tweet` (the tweet string) and `score` (the tweet evaluation) by joining data from both CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total different tweets evaluated so far: 411\n"
     ]
    }
   ],
   "source": [
    "# Build dictionary of tweets where key is the task__id\n",
    "own_tweets = []\n",
    "tweets_obj = {}\n",
    "for index, row in tweets_raw.iterrows():\n",
    "    own_tweets.append({\n",
    "        'id': row.id,\n",
    "        'tweet': row.text, \n",
    "        'polarity': row.polarity\n",
    "    })\n",
    "\n",
    "print('Total different tweets evaluated so far: %d' % len(own_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging\n",
    "\n",
    "Import libraries to read XML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import objectify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import/read most recent corpus (2017):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 values of sentiment: N, P, NONE, NEU\n",
    "xml = objectify.parse(open(corpus_tweets_2017_xml))\n",
    "root = xml.getroot()\n",
    "general_tweets_corpus_train_2017 = pd.DataFrame(columns=('content', 'polarity'))\n",
    "tweets = root.getchildren()\n",
    "for i in range(0, len(tweets)):\n",
    "    tweet = tweets[i]\n",
    "    row = dict(zip(['content', 'polarity'], [tweet.content.text, tweet.sentiment.polarity.value.text]))\n",
    "    row_s = pd.Series(row)\n",
    "    row_s.name = i\n",
    "    general_tweets_corpus_train_2017 = general_tweets_corpus_train_2017.append(row_s)\n",
    "    \n",
    "general_tweets_corpus_train_2017.to_csv(corpus_tweets_2017_csv, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import/read biggest corpus (2012), to concatenate it with the previous one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 values of sentiment: N, P, NONE, NEU\n",
    "xml = objectify.parse(open(corpus_tweets_2012_xml))\n",
    "root = xml.getroot()\n",
    "general_tweets_corpus_train_2012 = pd.DataFrame(columns=('content', 'polarity'))\n",
    "tweets = root.getchildren()\n",
    "for i in range(0, len(tweets)):\n",
    "    tweet = tweets[i]\n",
    "    row = dict(zip(['content', 'polarity'], [tweet.content.text, tweet.sentiments.polarity.value.text]))\n",
    "    row_s = pd.Series(row)\n",
    "    row_s.name = i\n",
    "    general_tweets_corpus_train_2012 = general_tweets_corpus_train_2012.append(row_s)\n",
    "    \n",
    "general_tweets_corpus_train_2012.to_csv(corpus_tweets_2012_csv, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate general corpus dataset with 2017 one, to have a better result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Ah vale, me suelta la puta subnormal, te estoy...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>#Chacón defiende que las primarias del @PSOE s...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Viernes negro: Aumenta el paro en Noviembre y ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>@PGimenezFuentes @CiudadanosCs paso, paso de t...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>#fb El ministro del Interior anuncia en @OndaC...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165</th>\n",
       "      <td>Montoro cree  q RTVE no tiene q competir con l...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>“@javiercasqueiro: Aquí está el roscón http://...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4761</th>\n",
       "      <td>;-)))) RT @soniachaconp: @mariviromero Gracias...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5853</th>\n",
       "      <td>Y si directores generales d la Administración ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3632</th>\n",
       "      <td>@sanchez_sonia No te has ido de ahí?. Buenos días</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content polarity\n",
       "62    Ah vale, me suelta la puta subnormal, te estoy...        N\n",
       "1468  #Chacón defiende que las primarias del @PSOE s...        P\n",
       "22    Viernes negro: Aumenta el paro en Noviembre y ...        N\n",
       "500   @PGimenezFuentes @CiudadanosCs paso, paso de t...        N\n",
       "1475  #fb El ministro del Interior anuncia en @OndaC...        P\n",
       "6165  Montoro cree  q RTVE no tiene q competir con l...        N\n",
       "1888  “@javiercasqueiro: Aquí está el roscón http://...        N\n",
       "4761  ;-)))) RT @soniachaconp: @mariviromero Gracias...        P\n",
       "5853  Y si directores generales d la Administración ...        N\n",
       "3632  @sanchez_sonia No te has ido de ahí?. Buenos días     NONE"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus = pd.concat([\n",
    "        general_tweets_corpus_train_2012,\n",
    "        general_tweets_corpus_train_2017\n",
    "    ])\n",
    "tweets_corpus.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus tweets: 8227\n"
     ]
    }
   ],
   "source": [
    "print('Total corpus tweets: %d' % len(tweets_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove tweets without polarity (polarity `NONE`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus = tweets_corpus.query('polarity != \"NONE\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove tweets that are only a link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus = tweets_corpus[-tweets_corpus.content.str.contains('^http.*$')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import regex tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we remove links, usernames, newline characters, multiple spaces and emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus_no_links = tweets_corpus\n",
    "\n",
    "# Remove links\n",
    "tweets_corpus_no_links['content'] = tweets_corpus_no_links['content'].map(lambda x: re.sub(re.compile('https?:\\/\\/t\\.co\\/[\\w]{8,8}'), '', x))\n",
    "\n",
    "# Remove usernames\n",
    "tweets_corpus_no_links['content'] = tweets_corpus_no_links['content'].map(lambda x: re.sub(re.compile('@[A-Za-z0-9_]+'), '', x))\n",
    "\n",
    "# Remove newline character\n",
    "tweets_corpus_no_links['content'] = tweets_corpus_no_links['content'].map(lambda x: re.sub(re.compile('[\\n\\r]+'), '', x))\n",
    "\n",
    "# Replace multiple spaces with single one\n",
    "tweets_corpus_no_links['content'] = tweets_corpus_no_links['content'].map(lambda x: re.sub(re.compile('[\\s]+'), ' ', x))\n",
    "\n",
    "# Remove emojis\n",
    "emoji_pattern = re.compile(u'['\n",
    "     u'\\U0001F300-\\U0001F64F'\n",
    "     u'\\U0001F680-\\U0001F6FF'\n",
    "     u'\\u2600-\\u26FF\\u2700-\\u27BF]+', \n",
    "     re.UNICODE)\n",
    "#tweets_corpus_no_links['content'] = tweets_corpus_no_links['content'].map(lambda x: re.sub(emoji_pattern, ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus tweets after cleaning: 6586\n"
     ]
    }
   ],
   "source": [
    "print('Total corpus tweets after cleaning: %d' % len(tweets_corpus_no_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6516</th>\n",
       "      <td>Deseo de mucho éxito al alcalde de Oropesa. Pa...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>¡Qué pintaza! Tanto la chistorra como el lomo...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>Adiós al maestro de humanidad: vía</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4584</th>\n",
       "      <td>En definitiva, un paso más para la creación de...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5739</th>\n",
       "      <td>Las simplezas de</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>Desde luego “: Pasado contrapasado no conlleva...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>Un buen botijo hace buen agua. Pero un buen bo...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>La reunión de la Mesa del Congreso convocada p...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5657</th>\n",
       "      <td>Quiero ser un alcalde para #Andalucía. Un alca...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>Y perdonad que no me haya hecho fotos con los ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content polarity\n",
       "6516  Deseo de mucho éxito al alcalde de Oropesa. Pa...        P\n",
       "787    ¡Qué pintaza! Tanto la chistorra como el lomo...        P\n",
       "2227                Adiós al maestro de humanidad: vía         N\n",
       "4584  En definitiva, un paso más para la creación de...        P\n",
       "5739                                  Las simplezas de         N\n",
       "2639  Desde luego “: Pasado contrapasado no conlleva...        N\n",
       "3140  Un buen botijo hace buen agua. Pero un buen bo...      NEU\n",
       "684   La reunión de la Mesa del Congreso convocada p...        N\n",
       "5657  Quiero ser un alcalde para #Andalucía. Un alca...        P\n",
       "1732  Y perdonad que no me haya hecho fotos con los ...        P"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and stemming\n",
    "\n",
    "Download Spanish stopwords in Spanish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jabatrox/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# Download spanish stopwords\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "spanish_stopwords = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get non-words, and extend array of non-words with characters `¿` and `¿`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "non_words = list(punctuation)\n",
    "\n",
    "# Add spanish punctuation\n",
    "non_words.extend(['¿', '¡'])\n",
    "non_words.extend(map(str,range(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define stemmer and tokenizer, based on previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer       \n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# based on http://www.cs.duke.edu/courses/spring14/compsci290/assignments/lab02.html\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    # remove non letters\n",
    "    text = ''.join([c for c in text if c not in non_words])\n",
    "    # tokenize\n",
    "    tokens =  word_tokenize(text)\n",
    "\n",
    "    # stem\n",
    "    try:\n",
    "        stems = stem_tokens(tokens, stemmer)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(text)\n",
    "        stems = ['']\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>Happy bday happy bday mom! Feliz cumple a la m...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>La mejor forma de garantizar la seguridad de n...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>RT Papelón #ZP entre el chipriota y el irlandé...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>¿Y tú de que trabajas? Yo ayudo a \"perfilar le...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>\" el cambio que proponemos es el cambio tranqu...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>que es un envidiosillo</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5250</th>\n",
       "      <td>El secreto para que una dieta funcione es deci...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>Patxi López reclama acercamiento de presos. 20:30</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6721</th>\n",
       "      <td>#Presupuestos Y ahora cuenta Montoro algunas d...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>#cabalgatasevilla llega a Pza.Magdalena.Espect...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content polarity\n",
       "2005  Happy bday happy bday mom! Feliz cumple a la m...        P\n",
       "1290  La mejor forma de garantizar la seguridad de n...        N\n",
       "343   RT Papelón #ZP entre el chipriota y el irlandé...        N\n",
       "689   ¿Y tú de que trabajas? Yo ayudo a \"perfilar le...        N\n",
       "2377  \" el cambio que proponemos es el cambio tranqu...        P\n",
       "923                             que es un envidiosillo         N\n",
       "5250  El secreto para que una dieta funcione es deci...        P\n",
       "2022  Patxi López reclama acercamiento de presos. 20:30        N\n",
       "6721  #Presupuestos Y ahora cuenta Montoro algunas d...        N\n",
       "1835  #cabalgatasevilla llega a Pza.Magdalena.Espect...        P"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert from strings to numerics the polarity values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jabatrox/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/jabatrox/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " 1    0.483602\n",
       "-1    0.394777\n",
       " 0    0.121622\n",
       "Name: polarity_bin, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus_no_links['polarity_bin'] = 0\n",
    "tweets_corpus_no_links.polarity_bin[tweets_corpus_no_links.polarity.isin(['P'])] = 1\n",
    "tweets_corpus_no_links.polarity_bin[tweets_corpus_no_links.polarity.isin(['N'])] = -1\n",
    "tweets_corpus_no_links.polarity_bin.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use SVC model with optimization via GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jabatrox/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words=['de', 'la'...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'vect__max_df': (0.5, 1.9), 'vect__min_df': (10, 20, 50), 'vect__max_features': (500, 1000), 'vect__ngram_range': ((1, 1), (1, 2)), 'rfc__n_estimators': [50, 100, 200], 'rfc__min_samples_split': [2, 3, 4, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "vectorizer = CountVectorizer(\n",
    "                analyzer = 'word',\n",
    "                tokenizer = tokenize,\n",
    "                lowercase = True,\n",
    "                stop_words = spanish_stopwords)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('rfc', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 1.9),\n",
    "    'vect__min_df': (10, 20,50),\n",
    "    'vect__max_features': (500, 1000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'rfc__n_estimators':[50, 100, 200],\n",
    "    'rfc__min_samples_split':[2, 3, 4, 5, 10]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1)\n",
    "grid_search.fit(tweets_corpus_no_links.content, tweets_corpus_no_links.polarity_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As long as we don't have binary classification, we must binarize the polarity and use a multiclass learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.preprocessing import label_binarize\\ntweets_corpus_no_links.polarity_bin = label_binarize(tweets_corpus_no_links.polarity_bin, classes=[-1, 0, 1])'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.preprocessing import label_binarize\n",
    "tweets_corpus_no_links.polarity_bin = label_binarize(tweets_corpus_no_links.polarity_bin, classes=[-1, 0, 1])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"params = {\\n    'vect__max_df': (0.5, 1.9),\\n    'vect__min_df': (10, 20,50),\\n    'vect__max_features': (500, 1000),\\n    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\\n    'cls__estimator__C': (0.2, 0.5, 0.7),\\n    'cls__estimator__loss': ('hinge', 'squared_hinge'),\\n    'cls__estimator__max_iter': (500, 1000)\\n      }\\ngs = GridSearchCV(pipeline, params, n_jobs=-1, cv=5, scoring='roc_auc')\\ngs.fit(tweets_corpus_no_links.content, tweets_corpus_no_links.polarity_bin)\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''params = {\n",
    "    'vect__max_df': (0.5, 1.9),\n",
    "    'vect__min_df': (10, 20,50),\n",
    "    'vect__max_features': (500, 1000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'cls__estimator__C': (0.2, 0.5, 0.7),\n",
    "    'cls__estimator__loss': ('hinge', 'squared_hinge'),\n",
    "    'cls__estimator__max_iter': (500, 1000)\n",
    "      }\n",
    "gs = GridSearchCV(pipeline, params, n_jobs=-1, cv=5, scoring='roc_auc')\n",
    "gs.fit(tweets_corpus_no_links.content, tweets_corpus_no_links.polarity_bin)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs.best_params_'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''gs.best_params_'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain that the best parameters are:\n",
    "\n",
    "{'cls__estimator__C': 0.2,\n",
    "\n",
    " 'cls__estimator__loss': 'hinge',\n",
    " \n",
    " 'cls__estimator__max_iter': 1000,\n",
    " \n",
    " 'vect__max_df': 1.9,\n",
    " \n",
    " 'vect__max_features': 1000,\n",
    " \n",
    " 'vect__min_df': 10,\n",
    " \n",
    " 'vect__ngram_range': (1, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.externals import joblib\\njoblib.dump(gs, 'grid_search.pkl')\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.externals import joblib\n",
    "joblib.dump(gs, 'grid_search.pkl')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "GridSearchCV(cv=None, error_score='raise',\n",
    "       estimator=Pipeline(memory=None,\n",
    "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
    "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
    "        ngram_range=(1, 1), preprocessor=None,\n",
    "        stop_words=['de', 'la'...n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False))]),\n",
    "       fit_params=None, iid=True, n_jobs=-1,\n",
    "       param_grid={'vect__max_df': (0.5, 1.9), 'vect__min_df': (10, 20, 50), 'vect__max_features': (500, 1000), 'vect__ngram_range': ((1, 1), (1, 2)), 'rfc__n_estimators': [50, 100, 200], 'rfc__min_samples_split': [2, 3, 4, 5, 10]},\n",
    "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
    "       scoring=None, verbose=0)\n",
    "'''\n",
    "\n",
    "\n",
    "model = LinearSVC(\n",
    "    C=.2, \n",
    "    loss='hinge', \n",
    "    max_iter=1000, \n",
    "    random_state=None, \n",
    "    penalty='l2'\n",
    ")\n",
    "\n",
    "# Define vectorizer with the previously created tokenizer and stopwords array\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    tokenizer = tokenize,\n",
    "    lowercase = True,\n",
    "    stop_words = spanish_stopwords,\n",
    "    min_df = 10,\n",
    "    max_df = 1.9,\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=1000\n",
    ")\n",
    "\n",
    "corpus_data_features = vectorizer.fit_transform(tweets_corpus_no_links.content)\n",
    "corpus_data_features_nd = corpus_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=tweets_corpus_no_links.polarity_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"scores = cross_val_score(\\n    model,\\n    corpus_data_features_nd[0:len(tweets_corpus_no_links)],\\n    y=tweets_corpus_no_links.polarity_bin,\\n    scoring='roc_auc',\\n    cv=5\\n    )\\n\\nscores.mean()\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''scores = cross_val_score(\n",
    "    model,\n",
    "    corpus_data_features_nd[0:len(tweets_corpus_no_links)],\n",
    "    y=tweets_corpus_no_links.polarity_bin,\n",
    "    scoring='roc_auc',\n",
    "    cv=5\n",
    "    )\n",
    "\n",
    "scores.mean()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polarity Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets: 177\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>42d8ce05</td>\n",
       "      <td>@maldiniplus Como dijo Draxler, el planteamien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>f067a08b</td>\n",
       "      <td>@moscu_toronto Pues cuando era pequeñito era d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>65da3719</td>\n",
       "      <td>@LlunaCatalana3 tv3 te els drets de la champio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>e71a115b</td>\n",
       "      <td>@EASPORTSEsp Griezmann no será por el partido ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2ddfa69e</td>\n",
       "      <td>@AlejandroNY75 @2010MisterChip Y peor. Elogia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>12d82762</td>\n",
       "      <td>EL DIRECTO EN EL QUE DjMaRiiO USÓ LA CAMISETA ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ebf7bff7</td>\n",
       "      <td>André Gomes no está dando el nivel pero los ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5a533794</td>\n",
       "      <td>¡EL INICIO DE UNA LEYENDA! 🔴🔵\\n\\n¿Qué momento ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>41de1a3a</td>\n",
       "      <td>La #EuropeaLeague el #Atlético se la tiene que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6eb6eb37</td>\n",
       "      <td>Neymar se fue al PSG en busca de “títulos”, si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text\n",
       "156  42d8ce05  @maldiniplus Como dijo Draxler, el planteamien...\n",
       "58   f067a08b  @moscu_toronto Pues cuando era pequeñito era d...\n",
       "137  65da3719  @LlunaCatalana3 tv3 te els drets de la champio...\n",
       "168  e71a115b  @EASPORTSEsp Griezmann no será por el partido ...\n",
       "71   2ddfa69e  @AlejandroNY75 @2010MisterChip Y peor. Elogia ...\n",
       "74   12d82762  EL DIRECTO EN EL QUE DjMaRiiO USÓ LA CAMISETA ...\n",
       "6    ebf7bff7  André Gomes no está dando el nivel pero los ab...\n",
       "42   5a533794  ¡EL INICIO DE UNA LEYENDA! 🔴🔵\\n\\n¿Qué momento ...\n",
       "45   41de1a3a  La #EuropeaLeague el #Atlético se la tiene que...\n",
       "77   6eb6eb37  Neymar se fue al PSG en busca de “títulos”, si..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_no_label = pd.read_csv(tweets_run_file, encoding='utf-8')\n",
    "print('Number of tweets: %d' % tweets_no_label.shape[0])\n",
    "tweets_no_label.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do some cleansing of the data, erasing again the links, usernames, newline characters, multiple spaces and emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove links\n",
    "tweets_no_label['text'] = tweets_no_label['text'].map(lambda x: re.sub(re.compile('https?:\\/\\/t\\.co\\/[\\w]{8,8}'), '', x))\n",
    "\n",
    "# Remove usernames\n",
    "tweets_no_label['text'] = tweets_no_label['text'].map(lambda x: re.sub(re.compile('@[A-Za-z0-9_]+'), '', x))\n",
    "\n",
    "# Remove newline character\n",
    "tweets_no_label['text'] = tweets_no_label['text'].map(lambda x: re.sub(re.compile('[\\n\\r]+'), '', x))\n",
    "\n",
    "# Replace multiple spaces with single one\n",
    "tweets_no_label['text'] = tweets_no_label['text'].map(lambda x: re.sub(re.compile('[\\s]+'), ' ', x))\n",
    "\n",
    "# Remove emojis\n",
    "emoji_pattern = re.compile(u'['\n",
    "     u'\\U0001F300-\\U0001F64F'\n",
    "     u'\\U0001F680-\\U0001F6FF'\n",
    "     u'\\u2600-\\u26FF\\u2700-\\u27BF]+', \n",
    "     re.UNICODE)\n",
    "#tweets_no_label['text'] = tweets_no_label['text'].map(lambda x: re.sub(emoji_pattern, ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>5b4878db</td>\n",
       "      <td>¿Aquellos casi atracos al Barça?, no se que d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>cee9b0a5</td>\n",
       "      <td>Que solo soy feliz con el atleti de madrid!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>be694b7a</td>\n",
       "      <td>Le tienen tanto odio, que hasta le critican po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>884da2b9</td>\n",
       "      <td>Resulta que el partido lo perdió el PSG por l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>b492b317</td>\n",
       "      <td>La 'rajada' de un ex objetivo del Barça sobre ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>484c36cf</td>\n",
       "      <td>La victoria de ayer a la prensa tampoco le val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a122a538</td>\n",
       "      <td>Un jugador brasileño de 21 años muy bueno q j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>97e7b943</td>\n",
       "      <td>Eso decidselo a Marca que cada día dan más ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79cdded5</td>\n",
       "      <td>FELICIDADES ¡¡ FRANCISCO¡¡🎂🎂🎂🎂🎂🎂🎂🎂🎂🎂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2687f611</td>\n",
       "      <td>El atleti no juega contra el PSG x q le elimi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text\n",
       "91   5b4878db   ¿Aquellos casi atracos al Barça?, no se que d...\n",
       "73   cee9b0a5      Que solo soy feliz con el atleti de madrid!!!\n",
       "97   be694b7a  Le tienen tanto odio, que hasta le critican po...\n",
       "105  884da2b9   Resulta que el partido lo perdió el PSG por l...\n",
       "68   b492b317  La 'rajada' de un ex objetivo del Barça sobre ...\n",
       "47   484c36cf  La victoria de ayer a la prensa tampoco le val...\n",
       "10   a122a538   Un jugador brasileño de 21 años muy bueno q j...\n",
       "158  97e7b943   Eso decidselo a Marca que cada día dan más ve...\n",
       "1    79cdded5               FELICIDADES ¡¡ FRANCISCO¡¡🎂🎂🎂🎂🎂🎂🎂🎂🎂🎂\n",
       "89   2687f611   El atleti no juega contra el PSG x q le elimi..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_no_label.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Language detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the fact that some tweets are in catalan, for language detection purposes we are only going to process about the ones in spanish for sentiment purposes.\n",
    "\n",
    "We use three different libraries for language detection and keep those tweets on which at least two of these libraries agree on the language being Spanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langid\n",
    "from langdetect import detect\n",
    "import textblob\n",
    "\n",
    "def langid_safe(tweet):\n",
    "    try:\n",
    "        return langid.classify(tweet)[0]\n",
    "    except Exception as e:\n",
    "        pass\n",
    "        \n",
    "def langdetect_safe(tweet):\n",
    "    try:\n",
    "        return detect(tweet)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "def textblob_safe(tweet):\n",
    "    try:\n",
    "        return textblob.TextBlob(tweet).detect_language()\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 3 new columns specifying the detected language of the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_no_label['lang_langid'] = tweets_no_label.text.apply(langid_safe)\n",
    "tweets_no_label['lang_langdetect'] = tweets_no_label.text.apply(langdetect_safe)\n",
    "tweets_no_label['lang_textblob'] = tweets_no_label.text.apply(textblob_safe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save as CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_no_label.to_csv('tweets_parsed.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the tweets in Spanish as follows:\n",
    "- If the language detected is Spanish by at least 2 libraries, leave.\n",
    "- If the language detected is Spanish in at least 1 library, print and append to the dataset manually.\n",
    "- If none of the languages detected is Spanish, remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets in Spanish: 150\n",
      "Tweets whose language is not clear: 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>lang_langid</th>\n",
       "      <th>lang_langdetect</th>\n",
       "      <th>lang_textblob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79cdded5</td>\n",
       "      <td>FELICIDADES ¡¡ FRANCISCO¡¡🎂🎂🎂🎂🎂🎂🎂🎂🎂🎂</td>\n",
       "      <td>zh</td>\n",
       "      <td>de</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26fe7471</td>\n",
       "      <td>Dedicado para: 0F</td>\n",
       "      <td>pt</td>\n",
       "      <td>pt</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cd0d8bcb</td>\n",
       "      <td>DRAXLER EXPLOTA vs el PSG | BALOTELLI ‘manda C...</td>\n",
       "      <td>es</td>\n",
       "      <td>ca</td>\n",
       "      <td>ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>97af720a</td>\n",
       "      <td>Para el que quiera ver el Barça hoy, es a las ...</td>\n",
       "      <td>ca</td>\n",
       "      <td>ca</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>09c0f4cc</td>\n",
       "      <td>El Barça Lassa deja casi vacía la enfermería 9...</td>\n",
       "      <td>an</td>\n",
       "      <td>ca</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5a533794</td>\n",
       "      <td>¡EL INICIO DE UNA LEYENDA! 🔴🔵¿Qué momento recu...</td>\n",
       "      <td>pt</td>\n",
       "      <td>pt</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>9046f222</td>\n",
       "      <td>ULTIMA HORA: EL PRESIDENTE DEL PSG LE OFRECE A...</td>\n",
       "      <td>tr</td>\n",
       "      <td>en</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5df2d140</td>\n",
       "      <td>Me ha gustado un vídeo de (tG - EL DIRECTO EN ...</td>\n",
       "      <td>gl</td>\n",
       "      <td>pt</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>c5343fa0</td>\n",
       "      <td>Y al Atleti que miura la va a tocar ahora en ...</td>\n",
       "      <td>ca</td>\n",
       "      <td>ca</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>12d82762</td>\n",
       "      <td>EL DIRECTO EN EL QUE DjMaRiiO USÓ LA CAMISETA ...</td>\n",
       "      <td>tr</td>\n",
       "      <td>pt</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>dcc02374</td>\n",
       "      <td>No es muy difícil Barça va Madrid</td>\n",
       "      <td>ca</td>\n",
       "      <td>ca</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>8f9d73cf</td>\n",
       "      <td>Cualquiera que no estuvieran ni Barça ni Madrid.</td>\n",
       "      <td>ca</td>\n",
       "      <td>ca</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6f30beca</td>\n",
       "      <td>CON LA MIRA PUESTA EN MALAGA.SE VIENE PARTIDO ...</td>\n",
       "      <td>ga</td>\n",
       "      <td>en</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>9cd8b232</td>\n",
       "      <td>LO QUE PASA ES QUE EL QUE HABLA PAJA SOY VOH ...</td>\n",
       "      <td>fi</td>\n",
       "      <td>pt</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>3c78bdb5</td>\n",
       "      <td>Sport, el Barça descartó en el pasado a Lucas ...</td>\n",
       "      <td>ca</td>\n",
       "      <td>ca</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>3beadb3a</td>\n",
       "      <td>📌Informa : ha fet cursa contínua avui a la Ciu...</td>\n",
       "      <td>es</td>\n",
       "      <td>ca</td>\n",
       "      <td>ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>c8cda282</td>\n",
       "      <td>Igual que los del Barça hacerse del PSG.</td>\n",
       "      <td>oc</td>\n",
       "      <td>ca</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>fce60e59</td>\n",
       "      <td>Iniesta inicia su plan en la Ciutat Esportiva ...</td>\n",
       "      <td>es</td>\n",
       "      <td>ca</td>\n",
       "      <td>ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>7bd204cc</td>\n",
       "      <td>Yo no me abono</td>\n",
       "      <td>pt</td>\n",
       "      <td>it</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text lang_langid  \\\n",
       "1    79cdded5               FELICIDADES ¡¡ FRANCISCO¡¡🎂🎂🎂🎂🎂🎂🎂🎂🎂🎂          zh   \n",
       "2    26fe7471                                  Dedicado para: 0F          pt   \n",
       "8    cd0d8bcb  DRAXLER EXPLOTA vs el PSG | BALOTELLI ‘manda C...          es   \n",
       "17   97af720a  Para el que quiera ver el Barça hoy, es a las ...          ca   \n",
       "40   09c0f4cc  El Barça Lassa deja casi vacía la enfermería 9...          an   \n",
       "42   5a533794  ¡EL INICIO DE UNA LEYENDA! 🔴🔵¿Qué momento recu...          pt   \n",
       "55   9046f222  ULTIMA HORA: EL PRESIDENTE DEL PSG LE OFRECE A...          tr   \n",
       "56   5df2d140  Me ha gustado un vídeo de (tG - EL DIRECTO EN ...          gl   \n",
       "72   c5343fa0   Y al Atleti que miura la va a tocar ahora en ...          ca   \n",
       "74   12d82762  EL DIRECTO EN EL QUE DjMaRiiO USÓ LA CAMISETA ...          tr   \n",
       "76   dcc02374                  No es muy difícil Barça va Madrid          ca   \n",
       "96   8f9d73cf   Cualquiera que no estuvieran ni Barça ni Madrid.          ca   \n",
       "112  6f30beca  CON LA MIRA PUESTA EN MALAGA.SE VIENE PARTIDO ...          ga   \n",
       "124  9cd8b232   LO QUE PASA ES QUE EL QUE HABLA PAJA SOY VOH ...          fi   \n",
       "125  3c78bdb5  Sport, el Barça descartó en el pasado a Lucas ...          ca   \n",
       "150  3beadb3a  📌Informa : ha fet cursa contínua avui a la Ciu...          es   \n",
       "152  c8cda282           Igual que los del Barça hacerse del PSG.          oc   \n",
       "166  fce60e59  Iniesta inicia su plan en la Ciutat Esportiva ...          es   \n",
       "170  7bd204cc                                     Yo no me abono          pt   \n",
       "\n",
       "    lang_langdetect lang_textblob  \n",
       "1                de            es  \n",
       "2                pt            es  \n",
       "8                ca            ca  \n",
       "17               ca            es  \n",
       "40               ca            es  \n",
       "42               pt            es  \n",
       "55               en            es  \n",
       "56               pt            es  \n",
       "72               ca            es  \n",
       "74               pt            es  \n",
       "76               ca            es  \n",
       "96               ca            es  \n",
       "112              en            es  \n",
       "124              pt            es  \n",
       "125              ca            es  \n",
       "150              ca            ca  \n",
       "152              ca            es  \n",
       "166              ca            ca  \n",
       "170              it            es  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leave tweets whose detected language is Spanish (majority):\n",
    "spanish_query = ''' (lang_langdetect == 'es' and lang_langid == 'es') or (lang_langdetect == 'es' and lang_textblob == 'es') or (lang_textblob == 'es' and lang_langid == 'es') '''\n",
    "tweets_spanish = tweets_no_label.query(spanish_query)\n",
    "\n",
    "print('Tweets in Spanish: %d' % tweets_spanish.shape[0])\n",
    "\n",
    "# Print tweets in doubtful language:\n",
    "nonspanish_query = ''' ((lang_langdetect != 'es' and lang_langid != 'es') or (lang_langdetect != 'es' and lang_textblob != 'es') or (lang_textblob != 'es' and lang_langid != 'es')) and (lang_textblob == 'es' or lang_langid == 'es' or lang_langdetect == 'es') '''\n",
    "tweets_doubtful = tweets_no_label.query(nonspanish_query)\n",
    "\n",
    "print('Tweets whose language is not clear: %d' % tweets_doubtful.shape[0])\n",
    "\n",
    "tweets_doubtful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets in Spanish: 169\n"
     ]
    }
   ],
   "source": [
    "# Append rest of the tweets in Spanish manually\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '79cdded5' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '26fe7471' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == 'cd0d8bcb' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '97af720a' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '09c0f4cc' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '5a533794' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '9046f222' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '5df2d140' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == 'c5343fa0' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '12d82762' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == 'dcc02374' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '8f9d73cf' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '6f30beca' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '9cd8b232' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '3c78bdb5' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '3beadb3a' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == 'c8cda282' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == 'fce60e59' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '7bd204cc' ''')])\n",
    "\n",
    "print('Tweets in Spanish: %d' % tweets_spanish.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(\n",
    "            analyzer = 'word',\n",
    "            tokenizer = tokenize,\n",
    "            lowercase = True,\n",
    "            stop_words = spanish_stopwords,\n",
    "            min_df = 10,\n",
    "            max_df = 1.9,\n",
    "            ngram_range=(1, 1),\n",
    "            max_features=1000\n",
    "            )),\n",
    "    ('cls', OneVsRestClassifier(LinearSVC(C=.2, loss='hinge',max_iter=1000,multi_class='ovr',\n",
    "             random_state=None,\n",
    "             penalty='l2',\n",
    "             ))),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(tweets_corpus_no_links.content, tweets_corpus_no_links.polarity_bin)\n",
    "tweets_no_label['polarity'] = pipeline.predict(tweets_no_label.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Como hará Griezmann para jugar en Madrid, Barç...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>El Barca aparte de ganar eso ha dominado el f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dedicado para: 0F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Seguro, el Madrid tiene mejor plantilla y da ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>No es muy difícil Barça va Madrid</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Más miedo al Barça que al PSG? Has mencionado ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>tv3 te els drets de la champions, però, no de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vengo 2/2 con los clasificados a Cuartos de Ch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>ESTA TARDE a las 18:45 se juega la SUPERCOPA D...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Creo q ustedes son del Madrid y quieren sacar...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Incomparecencia ayer del PSG. Alguien sabe si...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Hace 17 años, Messi por primera vez se puso la...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Really ? El Espanyol nos ganó. 🙄🙄Este año lo ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Vaya cabezazo del niño. Me recordó al de la f...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>¡EL INICIO DE UNA LEYENDA! 🔴🔵¿Qué momento recu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>OJITO al EJERCICIO de un niño de SEGUNDO de PR...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>A ver si encontráis algún tweet así a favor de...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Le tienen tanto odio, que hasta le critican po...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Madrid: Cuatro manifestaciones por el 8-M... y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>El que tiró la liga en septiembre el año pasa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Vaya, no nos lo esperábamos...; Es curioso com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Para el que quiera ver el Barça hoy, es a las ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Yo no me abono</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>André Gomes no está dando el nivel pero los ab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>No están trabajando en el juego, están cosien...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Jajajajaj puto Mario, pero Simón, la última v...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Md</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>lo terrible es que la afición del lo tolere, ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MESSI tira del carro del Barça y cuando se va...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Cuando el PSG permitió entrar a sus ultras jus...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  polarity\n",
       "12   Como hará Griezmann para jugar en Madrid, Barç...         1\n",
       "3     El Barca aparte de ganar eso ha dominado el f...         1\n",
       "2                                    Dedicado para: 0F         1\n",
       "23    Seguro, el Madrid tiene mejor plantilla y da ...        -1\n",
       "76                   No es muy difícil Barça va Madrid        -1\n",
       "106  Más miedo al Barça que al PSG? Has mencionado ...         1\n",
       "137   tv3 te els drets de la champions, però, no de...         1\n",
       "4    Vengo 2/2 con los clasificados a Cuartos de Ch...         1\n",
       "82   ESTA TARDE a las 18:45 se juega la SUPERCOPA D...         1\n",
       "120   Creo q ustedes son del Madrid y quieren sacar...        -1\n",
       "127   Incomparecencia ayer del PSG. Alguien sabe si...         1\n",
       "174  Hace 17 años, Messi por primera vez se puso la...         1\n",
       "108   Really ? El Espanyol nos ganó. 🙄🙄Este año lo ...        -1\n",
       "114   Vaya cabezazo del niño. Me recordó al de la f...        -1\n",
       "42   ¡EL INICIO DE UNA LEYENDA! 🔴🔵¿Qué momento recu...         1\n",
       "147  OJITO al EJERCICIO de un niño de SEGUNDO de PR...         1\n",
       "44   A ver si encontráis algún tweet así a favor de...        -1\n",
       "97   Le tienen tanto odio, que hasta le critican po...        -1\n",
       "81   Madrid: Cuatro manifestaciones por el 8-M... y...         1\n",
       "57    El que tiró la liga en septiembre el año pasa...         1\n",
       "131  Vaya, no nos lo esperábamos...; Es curioso com...         1\n",
       "17   Para el que quiera ver el Barça hoy, es a las ...         1\n",
       "170                                     Yo no me abono         1\n",
       "6    André Gomes no está dando el nivel pero los ab...         1\n",
       "113   No están trabajando en el juego, están cosien...        -1\n",
       "95    Jajajajaj puto Mario, pero Simón, la última v...        -1\n",
       "161                                                 Md         1\n",
       "162   lo terrible es que la afición del lo tolere, ...        -1\n",
       "11    MESSI tira del carro del Barça y cuando se va...        -1\n",
       "102  Cuando el PSG permitió entrar a sus ultras jus...        -1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_no_label[['text', 'polarity']].sample(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-convert polarity to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jabatrox/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/jabatrox/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Los parisinos no lo verán este año la famosa C...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Tienes razón.👍</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>No soy del Atleti pero me da pena lo que han e...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Lo q no comprendo es por q no salen comparand...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>¿Aquellos casi atracos al Barça?, no se que d...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Arthur prácticamente hecho, todo está firmado ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Cuenta la Leyenda que Todo comenzó hace 17 Año...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Este es nivel que tiene la gente. El Madrid nu...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Pobre Catalán!! Eres uno de esos del lazo Ama...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Hoy es el cumpleaños de Francisco Hervás Tirad...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Un jugador brasileño de 21 años muy bueno q j...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>LO QUE PASA ES QUE EL QUE HABLA PAJA SOY VOH ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>En esta temporada, City Vs Barça w5</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Vaya, no nos lo esperábamos...; Es curioso com...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>anyone in a match against barca</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>(Marca) Unos 1.300 efectivos velarán por la se...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Yo no me abono</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>En dias como hoy te das cuenta porque el R. M...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Y al Atleti que miura la va a tocar ahora en ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Félix Brych ayer en el partido de champions #P...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Hace 17 años, Messi por primera vez se puso la...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>¿Equipo de fútbol favorito? — No me gusta el f...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>VRSALJKO🎙: “No me quejé a nadie. Soy un profes...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DRAXLER EXPLOTA vs el PSG | BALOTELLI ‘manda C...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>¡EL DÍA QUE EL FUTBOL CAMBIÓ! 😍😍😍😍Hace 17 años...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Que noooo, así nos saca unas risas 😅😅😅</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>los que se clasifiquen ya son los mejores, Ba...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>No es muy difícil Barça va Madrid</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>4I</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>No están trabajando en el juego, están cosien...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text polarity_bin\n",
       "159  Los parisinos no lo verán este año la famosa C...     Negative\n",
       "48                                      Tienes razón.👍     Negative\n",
       "87   No soy del Atleti pero me da pena lo que han e...     Negative\n",
       "128   Lo q no comprendo es por q no salen comparand...     Negative\n",
       "91    ¿Aquellos casi atracos al Barça?, no se que d...     Negative\n",
       "139  Arthur prácticamente hecho, todo está firmado ...     Negative\n",
       "53   Cuenta la Leyenda que Todo comenzó hace 17 Año...     Positive\n",
       "111  Este es nivel que tiene la gente. El Madrid nu...     Negative\n",
       "25    Pobre Catalán!! Eres uno de esos del lazo Ama...     Negative\n",
       "104  Hoy es el cumpleaños de Francisco Hervás Tirad...     Positive\n",
       "10    Un jugador brasileño de 21 años muy bueno q j...     Positive\n",
       "124   LO QUE PASA ES QUE EL QUE HABLA PAJA SOY VOH ...     Negative\n",
       "130                En esta temporada, City Vs Barça w5     Positive\n",
       "131  Vaya, no nos lo esperábamos...; Es curioso com...     Positive\n",
       "61                     anyone in a match against barca     Positive\n",
       "39   (Marca) Unos 1.300 efectivos velarán por la se...     Positive\n",
       "170                                     Yo no me abono     Positive\n",
       "135   En dias como hoy te das cuenta porque el R. M...     Negative\n",
       "72    Y al Atleti que miura la va a tocar ahora en ...     Positive\n",
       "133  Félix Brych ayer en el partido de champions #P...     Positive\n",
       "171  Hace 17 años, Messi por primera vez se puso la...     Positive\n",
       "119  ¿Equipo de fútbol favorito? — No me gusta el f...     Positive\n",
       "30   VRSALJKO🎙: “No me quejé a nadie. Soy un profes...     Positive\n",
       "8    DRAXLER EXPLOTA vs el PSG | BALOTELLI ‘manda C...     Negative\n",
       "14   ¡EL DÍA QUE EL FUTBOL CAMBIÓ! 😍😍😍😍Hace 17 años...     Positive\n",
       "92              Que noooo, así nos saca unas risas 😅😅😅     Positive\n",
       "163   los que se clasifiquen ya son los mejores, Ba...     Positive\n",
       "76                   No es muy difícil Barça va Madrid     Negative\n",
       "164                                                 4I     Positive\n",
       "113   No están trabajando en el juego, están cosien...     Negative"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets_no_label.copy()\n",
    "tweets['polarity_bin'] = 'Neutral'\n",
    "tweets.polarity_bin[tweets.polarity.isin([1])] = 'Positive'\n",
    "tweets.polarity_bin[tweets.polarity.isin([-1])] = 'Negative'\n",
    "tweets.polarity_bin.value_counts(normalize=True)\n",
    "tweets[['text', 'polarity_bin']].sample(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove aux. columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.drop(['lang_langid', 'lang_langdetect','lang_textblob','polarity'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5d65492b</td>\n",
       "      <td>#BolitaPorfavorINFORMA: 📻💻⚽ Futbol Internacion...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>737f222e</td>\n",
       "      <td>Jajajajaj puto Mario, pero Simón, la última v...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>8675ca7f</td>\n",
       "      <td>Que noooo, así nos saca unas risas 😅😅😅</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>97af720a</td>\n",
       "      <td>Para el que quiera ver el Barça hoy, es a las ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>781bcd66</td>\n",
       "      <td>Hace 17 años, #Messi inició su camino con el 4...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>c5343fa0</td>\n",
       "      <td>Y al Atleti que miura la va a tocar ahora en ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>6d1bd293</td>\n",
       "      <td>Yo soy del Barça, hinchaba por Neymar</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>e859476c</td>\n",
       "      <td>“El fracaso, como la tristeza, es corrosivo cu...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>8d4d51db</td>\n",
       "      <td>Grandísimo. Y esto nunca lo comprenderá un tío...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1e08c5da</td>\n",
       "      <td>Soy 100% fans del Barça pero no caigo en eso....</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text polarity_bin\n",
       "60   5d65492b  #BolitaPorfavorINFORMA: 📻💻⚽ Futbol Internacion...     Positive\n",
       "95   737f222e   Jajajajaj puto Mario, pero Simón, la última v...     Negative\n",
       "92   8675ca7f             Que noooo, así nos saca unas risas 😅😅😅     Positive\n",
       "17   97af720a  Para el que quiera ver el Barça hoy, es a las ...     Positive\n",
       "85   781bcd66  Hace 17 años, #Messi inició su camino con el 4...     Positive\n",
       "72   c5343fa0   Y al Atleti que miura la va a tocar ahora en ...     Positive\n",
       "109  6d1bd293              Yo soy del Barça, hinchaba por Neymar     Positive\n",
       "64   e859476c  “El fracaso, como la tristeza, es corrosivo cu...     Positive\n",
       "84   8d4d51db  Grandísimo. Y esto nunca lo comprenderá un tío...     Negative\n",
       "110  1e08c5da   Soy 100% fans del Barça pero no caigo en eso....     Positive"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename column `polarity_bin` to `polarity`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.rename(columns={'polarity_bin': 'polarity'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export tweets as CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[['id', 'polarity']].to_csv('tweets_polarity_bin.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
