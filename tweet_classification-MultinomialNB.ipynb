{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet classification\n",
    "\n",
    "File names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_location = './'\n",
    "\n",
    "# To read\n",
    "tweets_raw_file = base_location + 'datasets/train.csv'\n",
    "tweets_run_file = base_location + 'datasets/test_nolabel.csv'\n",
    "corpus_tweets_2012_xml = base_location + 'general-train-tagged-3l.xml'\n",
    "corpus_tweets_2017_xml = base_location + 'intertass-train-tagged.xml'\n",
    "\n",
    "# To generate\n",
    "corpus_tweets_2012_csv = base_location + 'general-train-tagged-3l.csv'\n",
    "corpus_tweets_2017_csv = base_location + 'intertass-train-tagged.csv'\n",
    "corpus_tweets_csv = base_location + 'corpus_tweets.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets: 411\n",
      "Evaluated tweets so far: 177\n"
     ]
    }
   ],
   "source": [
    "tweets_raw = pd.read_csv(tweets_raw_file, encoding='utf-8')\n",
    "tweets_run = pd.read_csv(tweets_run_file, encoding='utf-8')\n",
    "\n",
    "print('Total tweets: %d' % len(tweets_raw))\n",
    "print('Evaluated tweets so far: %d' % len(tweets_run))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build new array of dictionaries with keys `id` (the task ID), `tweet` (the tweet string) and `score` (the tweet evaluation) by joining data from both CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total different tweets evaluated so far: 411\n"
     ]
    }
   ],
   "source": [
    "# Build dictionary of tweets where key is the task__id\n",
    "own_tweets = []\n",
    "tweets_obj = {}\n",
    "for index, row in tweets_raw.iterrows():\n",
    "    own_tweets.append({\n",
    "        'id': row.id,\n",
    "        'tweet': row.text, \n",
    "        'polarity': row.polarity\n",
    "    })\n",
    "\n",
    "print('Total different tweets evaluated so far: %d' % len(own_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging\n",
    "\n",
    "Import libraries to read XML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import objectify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import/read most recent corpus (2017):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4 values of sentiment: N, P, NONE, NEU\n",
    "xml = objectify.parse(open(corpus_tweets_2017_xml))\n",
    "root = xml.getroot()\n",
    "general_tweets_corpus_train_2017 = pd.DataFrame(columns=('content', 'polarity'))\n",
    "tweets = root.getchildren()\n",
    "for i in range(0, len(tweets)):\n",
    "    tweet = tweets[i]\n",
    "    row = dict(zip(['content', 'polarity'], [tweet.content.text, tweet.sentiment.polarity.value.text]))\n",
    "    row_s = pd.Series(row)\n",
    "    row_s.name = i\n",
    "    general_tweets_corpus_train_2017 = general_tweets_corpus_train_2017.append(row_s)\n",
    "    \n",
    "general_tweets_corpus_train_2017.to_csv(corpus_tweets_2017_csv, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import/read biggest corpus (2012), to concatenate it with the previous noe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4 values of sentiment: N, P, NONE, NEU\n",
    "xml = objectify.parse(open(corpus_tweets_2012_xml))\n",
    "root = xml.getroot()\n",
    "general_tweets_corpus_train_2012 = pd.DataFrame(columns=('content', 'polarity'))\n",
    "tweets = root.getchildren()\n",
    "for i in range(0, len(tweets)):\n",
    "    tweet = tweets[i]\n",
    "    row = dict(zip(['content', 'polarity'], [tweet.content.text, tweet.sentiments.polarity.value.text]))\n",
    "    row_s = pd.Series(row)\n",
    "    row_s.name = i\n",
    "    general_tweets_corpus_train_2012 = general_tweets_corpus_train_2012.append(row_s)\n",
    "    \n",
    "general_tweets_corpus_train_2012.to_csv(corpus_tweets_2012_csv, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate general corpus dataset with 2017 one, to have a better result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3989</th>\n",
       "      <td>A base de conquistar derechos de los trabajado...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6704</th>\n",
       "      <td>Los programas contra la violencia de género de...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Vale ya casi casi ... veo que cada minuto somo...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353</th>\n",
       "      <td>Me asombra el extraordinario poder que tiene l...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5065</th>\n",
       "      <td>Es de tal cinismo RT @juankicoino: @marivirome...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>RT \"@RguezBurgos: El Ibex sigue paradito. Apen...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>Rajoy a Amaiur: \"El tema es muy serio. La vida...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>También con la vicepresidenta y el secretario ...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6353</th>\n",
       "      <td>Aquí, el protagonista de la cerveza. http://t....</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>@Currice se que no me vas a leer pero si pudie...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content polarity\n",
       "3989  A base de conquistar derechos de los trabajado...        N\n",
       "6704  Los programas contra la violencia de género de...        P\n",
       "998   Vale ya casi casi ... veo que cada minuto somo...        P\n",
       "2353  Me asombra el extraordinario poder que tiene l...      NEU\n",
       "5065  Es de tal cinismo RT @juankicoino: @marivirome...        N\n",
       "4173  RT \"@RguezBurgos: El Ibex sigue paradito. Apen...        N\n",
       "1045  Rajoy a Amaiur: \"El tema es muy serio. La vida...        P\n",
       "3761  También con la vicepresidenta y el secretario ...      NEU\n",
       "6353  Aquí, el protagonista de la cerveza. http://t....     NONE\n",
       "495   @Currice se que no me vas a leer pero si pudie...        N"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus = pd.concat([\n",
    "        general_tweets_corpus_train_2012,\n",
    "        general_tweets_corpus_train_2017\n",
    "    ])\n",
    "tweets_corpus.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus tweets: 8227\n"
     ]
    }
   ],
   "source": [
    "print('Total corpus tweets: %d' % len(tweets_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove tweets without polarity (polarity `NONE`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_corpus = tweets_corpus.query('polarity != \"NONE\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove tweets that are only a link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_corpus = tweets_corpus[-tweets_corpus.content.str.contains('^http.*$')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import regex tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we remove links, usernames, newline characters, multiple spaces and emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_corpus_no_links = tweets_corpus\n",
    "\n",
    "# Remove links\n",
    "tweets_corpus_no_links['content'] = tweets_corpus_no_links['content'].map(lambda x: re.sub(re.compile('https?:\\/\\/t\\.co\\/[\\w]{8,8}'), '', x))\n",
    "\n",
    "# Remove usernames\n",
    "tweets_corpus_no_links['content'] = tweets_corpus_no_links['content'].map(lambda x: re.sub(re.compile('@[A-Za-z0-9_]+'), '', x))\n",
    "\n",
    "# Remove newline character\n",
    "tweets_corpus_no_links['content'] = tweets_corpus_no_links['content'].map(lambda x: re.sub(re.compile('[\\n\\r]+'), '', x))\n",
    "\n",
    "# Replace multiple spaces with single one\n",
    "tweets_corpus_no_links['content'] = tweets_corpus_no_links['content'].map(lambda x: re.sub(re.compile('[\\s]+'), ' ', x))\n",
    "\n",
    "# Remove emojis\n",
    "emoji_pattern = re.compile(u'['\n",
    "     u'\\U0001F300-\\U0001F64F'\n",
    "     u'\\U0001F680-\\U0001F6FF'\n",
    "     u'\\u2600-\\u26FF\\u2700-\\u27BF]+', \n",
    "     re.UNICODE)\n",
    "#tweets_corpus_no_links['content'] = tweets_corpus_no_links['content'].map(lambda x: re.sub(emoji_pattern, ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus tweets after cleaning: 6586\n"
     ]
    }
   ],
   "source": [
    "print('Total corpus tweets after cleaning: %d' % len(tweets_corpus_no_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>muchísimas gracias Luis Tú también eres un ej...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>La Junta Militar de Egipto levantará hoy la le...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>ya nos contarás si explota Europa (como dice ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>, vaya, felicidades atrasadas y muchas gracias</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>Para saber sobre como se las gasta la dictadur...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5902</th>\n",
       "      <td>Finalmente sólo ha habido un herido leve. Espe...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3807</th>\n",
       "      <td>Limpiar el cordón umbilical es una medida senc...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>yo no tengo ni idea y soy la primera que dice...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5016</th>\n",
       "      <td>Una de fakes de esos que todos los medios nos ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6897</th>\n",
       "      <td>Me gusta :) RT : Por qué decidí escribir un bl...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content polarity\n",
       "38     muchísimas gracias Luis Tú también eres un ej...        P\n",
       "2888  La Junta Militar de Egipto levantará hoy la le...        P\n",
       "308    ya nos contarás si explota Europa (como dice ...        N\n",
       "596     , vaya, felicidades atrasadas y muchas gracias         P\n",
       "4985  Para saber sobre como se las gasta la dictadur...        N\n",
       "5902  Finalmente sólo ha habido un herido leve. Espe...      NEU\n",
       "3807  Limpiar el cordón umbilical es una medida senc...        P\n",
       "225    yo no tengo ni idea y soy la primera que dice...        N\n",
       "5016  Una de fakes de esos que todos los medios nos ...        N\n",
       "6897  Me gusta :) RT : Por qué decidí escribir un bl...        P"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and stemming\n",
    "\n",
    "Download Spanish stopwords in Spanish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/dass/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download spanish stopwords\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "spanish_stopwords = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get non-words, and extend array of non-words with characters `¿` and `¿`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "non_words = list(punctuation)\n",
    "\n",
    "# Add spanish punctuation\n",
    "non_words.extend(['¿', '¡'])\n",
    "non_words.extend(map(str,range(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define stemmer and tokenizer, based on previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer       \n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# based on http://www.cs.duke.edu/courses/spring14/compsci290/assignments/lab02.html\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    # remove non letters\n",
    "    text = ''.join([c for c in text if c not in non_words])\n",
    "    # tokenize\n",
    "    tokens =  word_tokenize(text)\n",
    "\n",
    "    # stem\n",
    "    try:\n",
    "        stems = stem_tokens(tokens, stemmer)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(text)\n",
    "        stems = ['']\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Aunque pensaba que no podría hacerlo hasta el ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5400</th>\n",
       "      <td>La RUPTURA LABORAL LAPONIA es un sarcasmo en e...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3734</th>\n",
       "      <td>“: Qué botas más grandes y calentitas... O no?...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072</th>\n",
       "      <td>Listas de espera al alza en Catalunya, estalli...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5111</th>\n",
       "      <td>claro que si! Muero de ganas por ir ! Por lo p...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>Aquí esperando... Los viajes suelen tener retr...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Me dice un pajarito que ahora mismo no puede r...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6773</th>\n",
       "      <td>La cúpula de la Oficina Nacional de investigac...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5335</th>\n",
       "      <td>Buenos días,Hoy foto con el Fórmula1 d Fernand...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>Las Palmas nuevo y modesto líder de 1ª divisió...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content polarity\n",
       "16    Aunque pensaba que no podría hacerlo hasta el ...        P\n",
       "5400  La RUPTURA LABORAL LAPONIA es un sarcasmo en e...        N\n",
       "3734  “: Qué botas más grandes y calentitas... O no?...        P\n",
       "4072  Listas de espera al alza en Catalunya, estalli...        N\n",
       "5111  claro que si! Muero de ganas por ir ! Por lo p...        P\n",
       "1763  Aquí esperando... Los viajes suelen tener retr...        N\n",
       "40    Me dice un pajarito que ahora mismo no puede r...        N\n",
       "6773  La cúpula de la Oficina Nacional de investigac...        N\n",
       "5335  Buenos días,Hoy foto con el Fórmula1 d Fernand...        P\n",
       "836   Las Palmas nuevo y modesto líder de 1ª divisió...        P"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dass/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert from strings to numerics the polarity values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dass/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/dass/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " 1    0.483602\n",
       "-1    0.394777\n",
       " 0    0.121622\n",
       "Name: polarity_bin, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus_no_links['polarity_bin'] = 0\n",
    "tweets_corpus_no_links.polarity_bin[tweets_corpus_no_links.polarity.isin(['P'])] = 1\n",
    "tweets_corpus_no_links.polarity_bin[tweets_corpus_no_links.polarity.isin(['N'])] = -1\n",
    "tweets_corpus_no_links.polarity_bin.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use SVC model with optimization via GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "vectorizer = CountVectorizer(\n",
    "                analyzer = 'word',\n",
    "                tokenizer = tokenize,\n",
    "                lowercase = True,\n",
    "                stop_words = spanish_stopwords)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('cls', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As long as we don't have binary classification, we must binarize the polarity and use a multiclass learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0, 'class_prior': None, 'fit_prior': True}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultinomialNB().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.preprocessing import label_binarize\\ntweets_corpus_no_links.polarity_bin = label_binarize(tweets_corpus_no_links.polarity_bin, classes=[-1, 0, 1])'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.preprocessing import label_binarize\n",
    "tweets_corpus_no_links.polarity_bin = label_binarize(tweets_corpus_no_links.polarity_bin, classes=[-1, 0, 1])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words=['de', 'la'...1a0d1acae8>, vocabulary=None)), ('cls', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'cls__alpha': (0.001, 0.01, 0.1, 1)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'cls__alpha': (0.001, 0.01, 0.1, 1)\n",
    "      }\n",
    "gs = GridSearchCV(pipeline, params, n_jobs=-1, cv=5)\n",
    "gs.fit(tweets_corpus_no_links.content, tweets_corpus_no_links.polarity_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cls__alpha': 1}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain that the best parameters are:\n",
    "\n",
    "{'cls__alpha': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.externals import joblib\\njoblib.dump(gs, 'grid_search.pkl')\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.externals import joblib\n",
    "joblib.dump(gs, 'grid_search.pkl')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = MultinomialNB(\n",
    "    alpha=1\n",
    ")\n",
    "\n",
    "# Define vectorizer with the previously created tokenizer and stopwords array\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    tokenizer = tokenize,\n",
    "    lowercase = True,\n",
    "    stop_words = spanish_stopwords,\n",
    "    min_df = 10,\n",
    "    max_df = 1.9,\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=1000\n",
    ")\n",
    "\n",
    "corpus_data_features = vectorizer.fit_transform(tweets_corpus_no_links.content)\n",
    "corpus_data_features_nd = corpus_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=tweets_corpus_no_links.polarity_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"scores = cross_val_score(\\n    model,\\n    corpus_data_features_nd[0:len(tweets_corpus_no_links)],\\n    y=tweets_corpus_no_links.polarity_bin,\\n    scoring='roc_auc',\\n    cv=5\\n    )\\n\\nscores.mean()\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''scores = cross_val_score(\n",
    "    model,\n",
    "    corpus_data_features_nd[0:len(tweets_corpus_no_links)],\n",
    "    y=tweets_corpus_no_links.polarity_bin,\n",
    "    scoring='roc_auc',\n",
    "    cv=5\n",
    "    )\n",
    "\n",
    "scores.mean()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polarity Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets: 177\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>74acadab</td>\n",
       "      <td>@MiriamDakirFCB @Tocapilotes La Rata De PSG Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>d6e65407</td>\n",
       "      <td>@jmdelalamo Lo q no comprendo es por q no sale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>5f5fc452</td>\n",
       "      <td>@diariolagrada Pues nada, adeu y barca nova. Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>c2d98689</td>\n",
       "      <td>@putotrolaso @swivelFCB @LluisMascaro @sport E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ebf7bff7</td>\n",
       "      <td>André Gomes no está dando el nivel pero los ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6f30beca</td>\n",
       "      <td>CON LA MIRA PUESTA EN MALAGA.\\n\\nSE VIENE PART...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c4852036</td>\n",
       "      <td>Vengo 2/2 con los clasificados a Cuartos de Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>dcc02374</td>\n",
       "      <td>@bet365_es No es muy difícil Barça va Madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>5bc13938</td>\n",
       "      <td>@profenfurecido9 @Berlustinho Ése es el proble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>bf4b2c38</td>\n",
       "      <td>@ALEX15vs @FCBarcelona_es @FCBarcelona  https:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text\n",
       "35   74acadab  @MiriamDakirFCB @Tocapilotes La Rata De PSG Se...\n",
       "128  d6e65407  @jmdelalamo Lo q no comprendo es por q no sale...\n",
       "132  5f5fc452  @diariolagrada Pues nada, adeu y barca nova. Y...\n",
       "57   c2d98689  @putotrolaso @swivelFCB @LluisMascaro @sport E...\n",
       "6    ebf7bff7  André Gomes no está dando el nivel pero los ab...\n",
       "112  6f30beca  CON LA MIRA PUESTA EN MALAGA.\\n\\nSE VIENE PART...\n",
       "4    c4852036  Vengo 2/2 con los clasificados a Cuartos de Ch...\n",
       "76   dcc02374       @bet365_es No es muy difícil Barça va Madrid\n",
       "67   5bc13938  @profenfurecido9 @Berlustinho Ése es el proble...\n",
       "164  bf4b2c38  @ALEX15vs @FCBarcelona_es @FCBarcelona  https:..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_no_label = pd.read_csv(tweets_run_file, encoding='utf-8')\n",
    "print('Number of tweets: %d' % tweets_no_label.shape[0])\n",
    "tweets_no_label.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do some cleansing of the data, erasing again the links, usernames, newline characters, multiple spaces and emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove links\n",
    "tweets_no_label['text'] = tweets_no_label['text'].map(lambda x: re.sub(re.compile('https?:\\/\\/t\\.co\\/[\\w]{8,8}'), '', x))\n",
    "\n",
    "# Remove usernames\n",
    "tweets_no_label['text'] = tweets_no_label['text'].map(lambda x: re.sub(re.compile('@[A-Za-z0-9_]+'), '', x))\n",
    "\n",
    "# Remove newline character\n",
    "tweets_no_label['text'] = tweets_no_label['text'].map(lambda x: re.sub(re.compile('[\\n\\r]+'), '', x))\n",
    "\n",
    "# Replace multiple spaces with single one\n",
    "tweets_no_label['text'] = tweets_no_label['text'].map(lambda x: re.sub(re.compile('[\\s]+'), ' ', x))\n",
    "\n",
    "# Remove emojis\n",
    "emoji_pattern = re.compile(u'['\n",
    "     u'\\U0001F300-\\U0001F64F'\n",
    "     u'\\U0001F680-\\U0001F6FF'\n",
    "     u'\\u2600-\\u26FF\\u2700-\\u27BF]+', \n",
    "     re.UNICODE)\n",
    "#tweets_no_label['text'] = tweets_no_label['text'].map(lambda x: re.sub(emoji_pattern, ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>8b973b98</td>\n",
       "      <td>Algunos partidos de Cristiano en eliminatorias...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>31cb55fc</td>\n",
       "      <td>Cuenta la Leyenda que Todo comenzó hace 17 Año...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>9cd8b232</td>\n",
       "      <td>LO QUE PASA ES QUE EL QUE HABLA PAJA SOY VOH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26fe7471</td>\n",
       "      <td>Dedicado para: 0F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>d644c5df</td>\n",
       "      <td>En cuanto a Emery cada vez que tiene la oport...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2fb93730</td>\n",
       "      <td>Se le salió la barcelonitis al madridista oma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>a3798203</td>\n",
       "      <td>Lo siento, pero 3-0. Lo otro son campitos men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>b9a01810</td>\n",
       "      <td>#golazo sique tú sabes quien sería el capitán...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>bb0ee4ad</td>\n",
       "      <td>No me preocupa tanto el planteamiento táctico...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>4e3bdec7</td>\n",
       "      <td>Roban en la tienda oficial del en el Metropoli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text\n",
       "46   8b973b98  Algunos partidos de Cristiano en eliminatorias...\n",
       "53   31cb55fc  Cuenta la Leyenda que Todo comenzó hace 17 Año...\n",
       "124  9cd8b232   LO QUE PASA ES QUE EL QUE HABLA PAJA SOY VOH ...\n",
       "2    26fe7471                                  Dedicado para: 0F\n",
       "78   d644c5df   En cuanto a Emery cada vez que tiene la oport...\n",
       "157  2fb93730   Se le salió la barcelonitis al madridista oma...\n",
       "167  a3798203   Lo siento, pero 3-0. Lo otro son campitos men...\n",
       "59   b9a01810   #golazo sique tú sabes quien sería el capitán...\n",
       "33   bb0ee4ad   No me preocupa tanto el planteamiento táctico...\n",
       "142  4e3bdec7  Roban en la tienda oficial del en el Metropoli..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_no_label.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Language detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the fact that some tweets are in catalan, for language detection purposes we are only going to process about the ones in spanish for sentiment purposes.\n",
    "\n",
    "We use three different libraries for language detection and keep those tweets on which at least two of these libraries agree on the language being Spanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import langid\n",
    "from langdetect import detect\n",
    "import textblob\n",
    "\n",
    "def langid_safe(tweet):\n",
    "    try:\n",
    "        return langid.classify(tweet)[0]\n",
    "    except Exception as e:\n",
    "        pass\n",
    "        \n",
    "def langdetect_safe(tweet):\n",
    "    try:\n",
    "        return detect(tweet)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "def textblob_safe(tweet):\n",
    "    try:\n",
    "        return textblob.TextBlob(tweet).detect_language()\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 3 new columns specifying the detected language of the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_no_label['lang_langid'] = tweets_no_label.text.apply(langid_safe)\n",
    "tweets_no_label['lang_langdetect'] = tweets_no_label.text.apply(langdetect_safe)\n",
    "tweets_no_label['lang_textblob'] = tweets_no_label.text.apply(textblob_safe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save as CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_no_label.to_csv('tweets_parsed.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the tweets in Spanish as follows:\n",
    "- If the language detected is Spanish by at least 2 libraries, leave.\n",
    "- If the language detected is Spanish in at least 1 library, print and append to the dataset manually.\n",
    "- If none of the languages detected is Spanish, remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets in Spanish: 151\n",
      "Tweets whose language is not clear: 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>lang_langid</th>\n",
       "      <th>lang_langdetect</th>\n",
       "      <th>lang_textblob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79cdded5</td>\n",
       "      <td>FELICIDADES ¡¡ FRANCISCO¡¡🎂🎂🎂🎂🎂🎂🎂🎂🎂🎂</td>\n",
       "      <td>zh</td>\n",
       "      <td>de</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26fe7471</td>\n",
       "      <td>Dedicado para: 0F</td>\n",
       "      <td>pt</td>\n",
       "      <td>pt</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cd0d8bcb</td>\n",
       "      <td>DRAXLER EXPLOTA vs el PSG | BALOTELLI ‘manda C...</td>\n",
       "      <td>es</td>\n",
       "      <td>ca</td>\n",
       "      <td>ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>09c0f4cc</td>\n",
       "      <td>El Barça Lassa deja casi vacía la enfermería 9...</td>\n",
       "      <td>an</td>\n",
       "      <td>ca</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5a533794</td>\n",
       "      <td>¡EL INICIO DE UNA LEYENDA! 🔴🔵¿Qué momento recu...</td>\n",
       "      <td>pt</td>\n",
       "      <td>pt</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>9046f222</td>\n",
       "      <td>ULTIMA HORA: EL PRESIDENTE DEL PSG LE OFRECE A...</td>\n",
       "      <td>tr</td>\n",
       "      <td>en</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5df2d140</td>\n",
       "      <td>Me ha gustado un vídeo de (tG - EL DIRECTO EN ...</td>\n",
       "      <td>gl</td>\n",
       "      <td>pt</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>c5343fa0</td>\n",
       "      <td>Y al Atleti que miura la va a tocar ahora en ...</td>\n",
       "      <td>ca</td>\n",
       "      <td>ca</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>12d82762</td>\n",
       "      <td>EL DIRECTO EN EL QUE DjMaRiiO USÓ LA CAMISETA ...</td>\n",
       "      <td>tr</td>\n",
       "      <td>et</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>dcc02374</td>\n",
       "      <td>No es muy difícil Barça va Madrid</td>\n",
       "      <td>ca</td>\n",
       "      <td>ca</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>8f9d73cf</td>\n",
       "      <td>Cualquiera que no estuvieran ni Barça ni Madrid.</td>\n",
       "      <td>ca</td>\n",
       "      <td>ca</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6f30beca</td>\n",
       "      <td>CON LA MIRA PUESTA EN MALAGA.SE VIENE PARTIDO ...</td>\n",
       "      <td>ga</td>\n",
       "      <td>pt</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>9cd8b232</td>\n",
       "      <td>LO QUE PASA ES QUE EL QUE HABLA PAJA SOY VOH ...</td>\n",
       "      <td>fi</td>\n",
       "      <td>pt</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>3c78bdb5</td>\n",
       "      <td>Sport, el Barça descartó en el pasado a Lucas ...</td>\n",
       "      <td>ca</td>\n",
       "      <td>ca</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>3beadb3a</td>\n",
       "      <td>📌Informa : ha fet cursa contínua avui a la Ciu...</td>\n",
       "      <td>es</td>\n",
       "      <td>ca</td>\n",
       "      <td>ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>c8cda282</td>\n",
       "      <td>Igual que los del Barça hacerse del PSG.</td>\n",
       "      <td>oc</td>\n",
       "      <td>ca</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>fce60e59</td>\n",
       "      <td>Iniesta inicia su plan en la Ciutat Esportiva ...</td>\n",
       "      <td>es</td>\n",
       "      <td>ca</td>\n",
       "      <td>ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>7bd204cc</td>\n",
       "      <td>Yo no me abono</td>\n",
       "      <td>pt</td>\n",
       "      <td>it</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text lang_langid  \\\n",
       "1    79cdded5               FELICIDADES ¡¡ FRANCISCO¡¡🎂🎂🎂🎂🎂🎂🎂🎂🎂🎂          zh   \n",
       "2    26fe7471                                  Dedicado para: 0F          pt   \n",
       "8    cd0d8bcb  DRAXLER EXPLOTA vs el PSG | BALOTELLI ‘manda C...          es   \n",
       "40   09c0f4cc  El Barça Lassa deja casi vacía la enfermería 9...          an   \n",
       "42   5a533794  ¡EL INICIO DE UNA LEYENDA! 🔴🔵¿Qué momento recu...          pt   \n",
       "55   9046f222  ULTIMA HORA: EL PRESIDENTE DEL PSG LE OFRECE A...          tr   \n",
       "56   5df2d140  Me ha gustado un vídeo de (tG - EL DIRECTO EN ...          gl   \n",
       "72   c5343fa0   Y al Atleti que miura la va a tocar ahora en ...          ca   \n",
       "74   12d82762  EL DIRECTO EN EL QUE DjMaRiiO USÓ LA CAMISETA ...          tr   \n",
       "76   dcc02374                  No es muy difícil Barça va Madrid          ca   \n",
       "96   8f9d73cf   Cualquiera que no estuvieran ni Barça ni Madrid.          ca   \n",
       "112  6f30beca  CON LA MIRA PUESTA EN MALAGA.SE VIENE PARTIDO ...          ga   \n",
       "124  9cd8b232   LO QUE PASA ES QUE EL QUE HABLA PAJA SOY VOH ...          fi   \n",
       "125  3c78bdb5  Sport, el Barça descartó en el pasado a Lucas ...          ca   \n",
       "150  3beadb3a  📌Informa : ha fet cursa contínua avui a la Ciu...          es   \n",
       "152  c8cda282           Igual que los del Barça hacerse del PSG.          oc   \n",
       "166  fce60e59  Iniesta inicia su plan en la Ciutat Esportiva ...          es   \n",
       "170  7bd204cc                                     Yo no me abono          pt   \n",
       "\n",
       "    lang_langdetect lang_textblob  \n",
       "1                de            es  \n",
       "2                pt            es  \n",
       "8                ca            ca  \n",
       "40               ca            es  \n",
       "42               pt            es  \n",
       "55               en            es  \n",
       "56               pt            es  \n",
       "72               ca            es  \n",
       "74               et            es  \n",
       "76               ca            es  \n",
       "96               ca            es  \n",
       "112              pt            es  \n",
       "124              pt            es  \n",
       "125              ca            es  \n",
       "150              ca            ca  \n",
       "152              ca            es  \n",
       "166              ca            ca  \n",
       "170              it            es  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leave tweets whose detected language is Spanish (majority):\n",
    "spanish_query = ''' (lang_langdetect == 'es' and lang_langid == 'es') or (lang_langdetect == 'es' and lang_textblob == 'es') or (lang_textblob == 'es' and lang_langid == 'es') '''\n",
    "tweets_spanish = tweets_no_label.query(spanish_query)\n",
    "\n",
    "print('Tweets in Spanish: %d' % tweets_spanish.shape[0])\n",
    "\n",
    "# Print tweets in doubtful language:\n",
    "nonspanish_query = ''' ((lang_langdetect != 'es' and lang_langid != 'es') or (lang_langdetect != 'es' and lang_textblob != 'es') or (lang_textblob != 'es' and lang_langid != 'es')) and (lang_textblob == 'es' or lang_langid == 'es' or lang_langdetect == 'es') '''\n",
    "tweets_doubtful = tweets_no_label.query(nonspanish_query)\n",
    "\n",
    "print('Tweets whose language is not clear: %d' % tweets_doubtful.shape[0])\n",
    "\n",
    "tweets_doubtful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets in Spanish: 169\n"
     ]
    }
   ],
   "source": [
    "# Append rest of the tweets in Spanish manually\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '79cdded5' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '26fe7471' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == 'cd0d8bcb' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '97af720a' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '09c0f4cc' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '5a533794' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '9046f222' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '5df2d140' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == 'c5343fa0' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '12d82762' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == 'dcc02374' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '8f9d73cf' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '6f30beca' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '9cd8b232' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '3c78bdb5' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '3beadb3a' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == 'c8cda282' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == 'fce60e59' ''')])\n",
    "tweets_spanish = pd.concat([tweets_spanish, tweets_doubtful.query(''' id == '7bd204cc' ''')])\n",
    "\n",
    "print('Tweets in Spanish: %d' % tweets_spanish.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(\n",
    "            analyzer = 'word',\n",
    "            tokenizer = tokenize,\n",
    "            lowercase = True,\n",
    "            stop_words = spanish_stopwords,\n",
    "            min_df = 10,\n",
    "            max_df = 1.9,\n",
    "            ngram_range=(1, 1),\n",
    "            max_features=1000\n",
    "            )),\n",
    "    ('cls', MultinomialNB(alpha=1\n",
    "             )),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline.fit(tweets_corpus_no_links.content, tweets_corpus_no_links.polarity_bin)\n",
    "tweets_no_label['polarity'] = pipeline.predict(tweets_no_label.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Y al Atleti que miura la va a tocar ahora en ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Le dare merito al madrid el dia q vosotros re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Se llevaron todas las Champions, creo.</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>#LegitimosUsuarios de #Armas inspeccionados, y...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Tu diciendo que no deja de pensar en el Barça...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pero que te crees? Xk os sorprende lo de este...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>VRSALJKO🎙: “No me quejé a nadie. Soy un profes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>“El fracaso, como la tristeza, es corrosivo cu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MESSI tira del carro del Barça y cuando se va...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Neymar se fue al PSG en busca de “títulos”, si...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Yo soy del Barça, hinchaba por Neymar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Cuenta la Leyenda que Todo comenzó hace 17 Año...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>EL DIRECTO EN EL QUE DjMaRiiO USÓ LA CAMISETA ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>????? A ver subnormal, creo que no se te da e...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>4I</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Veremos si es tan superior cuándo juegue cont...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>El Barca aparte de ganar eso ha dominado el f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Griezmann no será por el partido ante el Barç...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Como hará Griezmann para jugar en Madrid, Barç...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Pues nada, adeu y barca nova. Y mientras tant...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Se le viene Real Madrid, Barça o Bayern Munich...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Este es nivel que tiene la gente. El Madrid nu...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Seguro, el Madrid tiene mejor plantilla y da ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>OJITO al EJERCICIO de un niño de SEGUNDO de PR...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>No pusieron los 5 al barcaAH NO PARAA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>La \"rajada\" de un ex objetivo del Barça sobre ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>📌Informa : ha fet cursa contínua avui a la Ciu...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Hace 17 años, #Messi inició su camino con el 4...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Claro, no es jugador del Barça. Lo que hizo e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>M. Bartra debió quedarse en el Barcelona, una ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  polarity\n",
       "72    Y al Atleti que miura la va a tocar ahora en ...         1\n",
       "160   Le dare merito al madrid el dia q vosotros re...         1\n",
       "69              Se llevaron todas las Champions, creo.        -1\n",
       "155  #LegitimosUsuarios de #Armas inspeccionados, y...        -1\n",
       "75    Tu diciendo que no deja de pensar en el Barça...         0\n",
       "5     Pero que te crees? Xk os sorprende lo de este...        -1\n",
       "30   VRSALJKO🎙: “No me quejé a nadie. Soy un profes...         1\n",
       "64   “El fracaso, como la tristeza, es corrosivo cu...         1\n",
       "11    MESSI tira del carro del Barça y cuando se va...         1\n",
       "77   Neymar se fue al PSG en busca de “títulos”, si...         1\n",
       "109              Yo soy del Barça, hinchaba por Neymar         1\n",
       "53   Cuenta la Leyenda que Todo comenzó hace 17 Año...         1\n",
       "74   EL DIRECTO EN EL QUE DjMaRiiO USÓ LA CAMISETA ...         1\n",
       "115   ????? A ver subnormal, creo que no se te da e...        -1\n",
       "164                                                 4I         1\n",
       "50    Veremos si es tan superior cuándo juegue cont...         1\n",
       "3     El Barca aparte de ganar eso ha dominado el f...         1\n",
       "168   Griezmann no será por el partido ante el Barç...         1\n",
       "12   Como hará Griezmann para jugar en Madrid, Barç...         1\n",
       "132   Pues nada, adeu y barca nova. Y mientras tant...        -1\n",
       "121  Se le viene Real Madrid, Barça o Bayern Munich...         0\n",
       "111  Este es nivel que tiene la gente. El Madrid nu...        -1\n",
       "23    Seguro, el Madrid tiene mejor plantilla y da ...         0\n",
       "147  OJITO al EJERCICIO de un niño de SEGUNDO de PR...         1\n",
       "149              No pusieron los 5 al barcaAH NO PARAA         1\n",
       "122  La \"rajada\" de un ex objetivo del Barça sobre ...        -1\n",
       "150  📌Informa : ha fet cursa contínua avui a la Ciu...        -1\n",
       "85   Hace 17 años, #Messi inició su camino con el 4...         1\n",
       "116   Claro, no es jugador del Barça. Lo que hizo e...         0\n",
       "101  M. Bartra debió quedarse en el Barcelona, una ...         1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_no_label[['text', 'polarity']].sample(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-convert polarity to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dass/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/dass/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>No están trabajando en el juego, están cosien...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Yo soy del Barça, hinchaba por Neymar</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Soy 100% fans del Barça pero no caigo en eso....</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Please RT!! #barcelona #fcbarcelona #Barca #fc...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Ése es el problema. No todos se han formado e...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Cuidado! Recodad que el Málaga por más pésimo...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pero porque la ganase el Atm o porque la perd...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Iniesta inicia su plan en la Ciutat Esportiva ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Please RT!! #atleti #atletico #ATM El fisio ?a...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Como hará Griezmann para jugar en Madrid, Barç...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hoy juega mi querido Barça y mi cuerpo y garga...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>A este Dios de este competicion quitas sus ac...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Vaya, no nos lo esperábamos...; Es curioso com...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>tv3 te els drets de la champions, però, no de...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Neymar se fue al PSG en busca de “títulos”, si...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>La \"rajada\" de un ex objetivo del Barça sobre ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>📌Informa : ha fet cursa contínua avui a la Ciu...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>los que se clasifiquen ya son los mejores, Ba...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Tu diciendo que no deja de pensar en el Barça...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Despres de les noticies del Barça, futbolisti...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>El Madrid se siente invencible en su competici...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lucas Vázquez iguala a #Messi #como los máximo...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>La Rata De PSG Se Fue Del Barca Cuando El Bar...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Que solo soy feliz con el atleti de madrid!!!</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Y peor. Elogia al citi y dice q Alexis es del...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Que morro tienen, si en los últimos años no f...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>No me preocupa tanto el planteamiento táctico...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>El típico indiecito q habla pestes del mas Gl...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Los parisinos no lo verán este año la famosa C...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Recién me compro el conjunto del Barça y ya sa...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text polarity_bin\n",
       "113   No están trabajando en el juego, están cosien...     Negative\n",
       "109              Yo soy del Barça, hinchaba por Neymar     Positive\n",
       "110   Soy 100% fans del Barça pero no caigo en eso....     Positive\n",
       "80   Please RT!! #barcelona #fcbarcelona #Barca #fc...     Positive\n",
       "67    Ése es el problema. No todos se han formado e...     Negative\n",
       "31    Cuidado! Recodad que el Málaga por más pésimo...     Negative\n",
       "18    Pero porque la ganase el Atm o porque la perd...      Neutral\n",
       "166  Iniesta inicia su plan en la Ciutat Esportiva ...     Positive\n",
       "43   Please RT!! #atleti #atletico #ATM El fisio ?a...     Positive\n",
       "12   Como hará Griezmann para jugar en Madrid, Barç...     Positive\n",
       "9    Hoy juega mi querido Barça y mi cuerpo y garga...     Positive\n",
       "65    A este Dios de este competicion quitas sus ac...     Negative\n",
       "131  Vaya, no nos lo esperábamos...; Es curioso com...     Positive\n",
       "137   tv3 te els drets de la champions, però, no de...     Positive\n",
       "77   Neymar se fue al PSG en busca de “títulos”, si...     Positive\n",
       "122  La \"rajada\" de un ex objetivo del Barça sobre ...     Negative\n",
       "150  📌Informa : ha fet cursa contínua avui a la Ciu...     Negative\n",
       "163   los que se clasifiquen ya son los mejores, Ba...     Positive\n",
       "75    Tu diciendo que no deja de pensar en el Barça...      Neutral\n",
       "63    Despres de les noticies del Barça, futbolisti...     Positive\n",
       "118  El Madrid se siente invencible en su competici...     Positive\n",
       "98   Lucas Vázquez iguala a #Messi #como los máximo...     Negative\n",
       "35    La Rata De PSG Se Fue Del Barca Cuando El Bar...     Positive\n",
       "73       Que solo soy feliz con el atleti de madrid!!!     Positive\n",
       "71    Y peor. Elogia al citi y dice q Alexis es del...     Negative\n",
       "138   Que morro tienen, si en los últimos años no f...      Neutral\n",
       "33    No me preocupa tanto el planteamiento táctico...     Negative\n",
       "151   El típico indiecito q habla pestes del mas Gl...     Negative\n",
       "159  Los parisinos no lo verán este año la famosa C...     Negative\n",
       "13   Recién me compro el conjunto del Barça y ya sa...     Positive"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets_no_label.copy()\n",
    "tweets['polarity_bin'] = 'Neutral'\n",
    "tweets.polarity_bin[tweets.polarity.isin([1])] = 'Positive'\n",
    "tweets.polarity_bin[tweets.polarity.isin([-1])] = 'Negative'\n",
    "tweets.polarity_bin.value_counts(normalize=True)\n",
    "tweets[['text', 'polarity_bin']].sample(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove aux. columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets.drop(['lang_langid', 'lang_langdetect','lang_textblob','polarity'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>c5343fa0</td>\n",
       "      <td>Y al Atleti que miura la va a tocar ahora en ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>66d69741</td>\n",
       "      <td>Como hará Griezmann para jugar en Madrid, Barç...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>94687a81</td>\n",
       "      <td>Es un torneito molero con premio mas o menos ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>636c8da5</td>\n",
       "      <td>MESSI tira del carro del Barça y cuando se va...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>b2bde016</td>\n",
       "      <td>El Espanyol ha sacado más puntos contra el Ma...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>96ef2a30</td>\n",
       "      <td>Y de k vale cumplir siemore salimos maltratad...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>8d4d51db</td>\n",
       "      <td>Grandísimo. Y esto nunca lo comprenderá un tío...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5b13b74a</td>\n",
       "      <td>Seguro, el Madrid tiene mejor plantilla y da ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>7178e29d</td>\n",
       "      <td>Le dare merito al madrid el dia q vosotros re...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>eb2cb9f4</td>\n",
       "      <td>Es que son muy ridículos. Perder contra el Ba...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text polarity_bin\n",
       "72   c5343fa0   Y al Atleti que miura la va a tocar ahora en ...     Positive\n",
       "12   66d69741  Como hará Griezmann para jugar en Madrid, Barç...     Positive\n",
       "52   94687a81   Es un torneito molero con premio mas o menos ...     Positive\n",
       "11   636c8da5   MESSI tira del carro del Barça y cuando se va...     Positive\n",
       "28   b2bde016   El Espanyol ha sacado más puntos contra el Ma...     Negative\n",
       "175  96ef2a30   Y de k vale cumplir siemore salimos maltratad...     Negative\n",
       "84   8d4d51db  Grandísimo. Y esto nunca lo comprenderá un tío...     Negative\n",
       "23   5b13b74a   Seguro, el Madrid tiene mejor plantilla y da ...      Neutral\n",
       "160  7178e29d   Le dare merito al madrid el dia q vosotros re...     Positive\n",
       "176  eb2cb9f4   Es que son muy ridículos. Perder contra el Ba...      Neutral"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename column `polarity_bin` to `polarity`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = tweets.rename(columns={'polarity_bin': 'polarity'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export tweets as CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets[['id', 'polarity']].to_csv('tweets_polarity_bin_multinomial.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
