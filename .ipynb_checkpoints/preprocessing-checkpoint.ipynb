{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet classification\n",
    "\n",
    "File names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read\n",
    "test_tweets_raw = 'datasets/test_nolabel.csv'\n",
    "train_tweets_raw = 'datasets/train.csv'\n",
    "corpus_tweets_2012_xml = 'general-train-tagged-3l.xml'\n",
    "corpus_tweets_2017_xml = 'intertass-train-tagged.xml'\n",
    "emojis_csv = 'emojis.csv'\n",
    "\n",
    "# To generate\n",
    "corpus_tweets_2012_csv = 'general-train-tagged-3l.csv'\n",
    "corpus_tweets_2017_csv = 'intertass-train-tagged.csv'\n",
    "corpus_tweets_csv = 'corpus_tweets_preprocessed.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Pandas and Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets to evaluate: 177\n",
      "Evaluated tweets so far: 411\n"
     ]
    }
   ],
   "source": [
    "tweets_test = pd.read_csv(test_tweets_raw, encoding='utf-8')\n",
    "tweets_train = pd.read_csv(train_tweets_raw, encoding='utf-8')\n",
    "\n",
    "print('Total tweets to evaluate: %d' % len(tweets_test))\n",
    "print('Evaluated tweets so far: %d' % len(tweets_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging\n",
    "\n",
    "Import libraries to read XML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import objectify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import/read most recent corpus (2017):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 values of sentiment: N, P, NONE, NEU\n",
    "xml = objectify.parse(open(corpus_tweets_2017_xml))\n",
    "root = xml.getroot()\n",
    "general_tweets_corpus_train_2017 = pd.DataFrame(columns=('content', 'polarity'))\n",
    "tweets = root.getchildren()\n",
    "for i in range(0, len(tweets)):\n",
    "    tweet = tweets[i]\n",
    "    row = dict(zip(['content', 'polarity'], [tweet.content.text, tweet.sentiment.polarity.value.text]))\n",
    "    row_s = pd.Series(row)\n",
    "    row_s.name = i\n",
    "    general_tweets_corpus_train_2017 = general_tweets_corpus_train_2017.append(row_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import/read biggest corpus (2012), to concatenate it with the previous one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 values of sentiment: N, P, NONE, NEU\n",
    "xml = objectify.parse(open(corpus_tweets_2012_xml))\n",
    "root = xml.getroot()\n",
    "general_tweets_corpus_train_2012 = pd.DataFrame(columns=('content', 'polarity'))\n",
    "tweets = root.getchildren()\n",
    "for i in range(0, len(tweets)):\n",
    "    tweet = tweets[i]\n",
    "    row = dict(zip(['content', 'polarity'], [tweet.content.text, tweet.sentiments.polarity.value.text]))\n",
    "    row_s = pd.Series(row)\n",
    "    row_s.name = i\n",
    "    general_tweets_corpus_train_2012 = general_tweets_corpus_train_2012.append(row_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import/read emoji sentiment dataset, to concatenate with the previous ones. Build column `polarity` according to the following criteria:\n",
    "- If sentiment score is between -1 and -0.2, consider it a **negative** sentiment (`N`).\n",
    "- If sentiment score is between -0.2 and 0.2, consider it a **neutral** sentiment (`NEU`).\n",
    "- If sentiment score is between 0.2 and 1, consider it a **positive** sentiment (`P`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angel.munozs/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/angel.munozs/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# Read emojis CSV\n",
    "emoji_dataset = pd.read_csv(emojis_csv, encoding='utf-8')\n",
    "\n",
    "# Init dataframe to append to corpus\n",
    "emoji_corpus = pd.DataFrame(columns=('content', 'polarity'))\n",
    "\n",
    "# Build column 'polarity\n",
    "emoji_dataset['polarity'] = 'NEU'\n",
    "emoji_dataset['polarity'][emoji_dataset.sentiment < -0.2] = 'N'\n",
    "emoji_dataset['polarity'][emoji_dataset.sentiment > 0.2] = 'P'\n",
    "\n",
    "for i, row in emoji_dataset.iterrows():\n",
    "    new_row = dict(zip(['content', 'polarity'], [chr(int(row.emoji, 16)), row.polarity]))\n",
    "    row_s = pd.Series(new_row)\n",
    "    row_s.name = i\n",
    "    emoji_corpus = emoji_corpus.append(row_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate general corpus dataset with 2017 one, to have a better result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus = pd.concat([\n",
    "        general_tweets_corpus_train_2012,\n",
    "        general_tweets_corpus_train_2017,\n",
    "        emoji_corpus\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import regex tools\n",
    "import re\n",
    "\n",
    "# Build emoji regex\n",
    "emoji_string = '|'.join(emoji_corpus['content'])\n",
    "emoji_regex = re.compile(r'(%s)' % emoji_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6839</th>\n",
       "      <td>Buenos dias amigos!direccion mallorca a dar nu...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6436</th>\n",
       "      <td>Planeta creativo: nuevo placer otra interesant...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3025</th>\n",
       "      <td>No somos telesucesos, si quiere informaciÃ³n co...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3344</th>\n",
       "      <td>Nuestro grupo quiere acercar mÃ¡s la actividad ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>Â¿Donde estÃ¡ UrdangarÃ­n? Toda Barcelona le busc...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3934</th>\n",
       "      <td>Los medios extranjeros coinciden en que el jui...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>Os doy una pista: Se va a sentir muy identific...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5890</th>\n",
       "      <td>A dÃ­a de hoy 53.220 â€œ@cora_alvarez: @pedroj_ra...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>Nunca te acostarÃ¡s sin tener un desengaÃ±o mÃ¡s.</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>ðŸ“¹</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content polarity\n",
       "6839  Buenos dias amigos!direccion mallorca a dar nu...      NEU\n",
       "6436  Planeta creativo: nuevo placer otra interesant...        P\n",
       "3025  No somos telesucesos, si quiere informaciÃ³n co...        P\n",
       "3344  Nuestro grupo quiere acercar mÃ¡s la actividad ...        P\n",
       "2671  Â¿Donde estÃ¡ UrdangarÃ­n? Toda Barcelona le busc...        N\n",
       "3934  Los medios extranjeros coinciden en que el jui...        N\n",
       "623   Os doy una pista: Se va a sentir muy identific...        P\n",
       "5890  A dÃ­a de hoy 53.220 â€œ@cora_alvarez: @pedroj_ra...        P\n",
       "2626     Nunca te acostarÃ¡s sin tener un desengaÃ±o mÃ¡s.        N\n",
       "578                                                   ðŸ“¹        P"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus tweets: 8978\n"
     ]
    }
   ],
   "source": [
    "print('Total corpus tweets: %d' % len(tweets_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove tweets from the corpus where `polarity` is `NONE`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove tweets with polarity 'NONE'\n",
    "tweets_corpus = tweets_corpus.query('polarity != \"NONE\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tweet cleaning function\n",
    "def clean_tweets(tweets, col_name):\n",
    "    # Remove links\n",
    "    tweets[col_name] = tweets[col_name].map(lambda x: re.sub(re.compile('https?:\\/\\/t\\.co\\/[\\w]{8,8}'), '', x))\n",
    "    # Remove usernames\n",
    "    tweets[col_name] = tweets[col_name].map(lambda x: re.sub(re.compile('@[A-Za-z0-9_]+'), '', x))\n",
    "    # Remove newline character\n",
    "    tweets[col_name] = tweets[col_name].map(lambda x: re.sub(re.compile('[\\n\\r]+'), '', x))\n",
    "    # Insert space between emojis\n",
    "    tweets[col_name] = tweets[col_name].map(lambda x: re.sub(emoji_regex, r' \\1 ', x))\n",
    "    # Replace multiple spaces with single one\n",
    "    tweets[col_name] = tweets[col_name].map(lambda x: re.sub(re.compile('[\\s]+'), ' ', x))\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we clean the train and test data with the previous function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus = clean_tweets(tweets_corpus, 'content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus tweets after cleaning: 7356\n"
     ]
    }
   ],
   "source": [
    "print('Total corpus tweets after cleaning: %d' % len(tweets_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Granado reconoce que da los datos de paro \"con...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>RT : Con el carro de Manolo Escobar? â€œ: Â¿DÃ³nde...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>lo mas gracioso es que diciendo esas cosas so...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6040</th>\n",
       "      <td>La encuesta de EP da mayorÃ­a absoluta al PP en...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>El jurado popular considera inocentes a Camps ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>Ana Diaz , grupo Abengoa : \" En #Andalucia som...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5089</th>\n",
       "      <td>RT : Jueves de REVISTA! En Portada HOY Mujer :...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6226</th>\n",
       "      <td>Buenas noches twitteros,como me gusta el twitt...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Un placer! ;-) RT : Vemos a , habitual en nues...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4971</th>\n",
       "      <td>Ofrenda floral a Blas Infante</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content polarity\n",
       "54    Granado reconoce que da los datos de paro \"con...        N\n",
       "1914  RT : Con el carro de Manolo Escobar? â€œ: Â¿DÃ³nde...        N\n",
       "361    lo mas gracioso es que diciendo esas cosas so...        N\n",
       "6040  La encuesta de EP da mayorÃ­a absoluta al PP en...      NEU\n",
       "2961  El jurado popular considera inocentes a Camps ...        P\n",
       "4275  Ana Diaz , grupo Abengoa : \" En #Andalucia som...        P\n",
       "5089  RT : Jueves de REVISTA! En Portada HOY Mujer :...        P\n",
       "6226  Buenas noches twitteros,como me gusta el twitt...        P\n",
       "620   Un placer! ;-) RT : Vemos a , habitual en nues...        P\n",
       "4971                     Ofrenda floral a Blas Infante         P"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export corpus tweets as CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus.to_csv(corpus_tweets_csv, encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
