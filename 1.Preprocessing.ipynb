{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of the Tweets\n",
    "All methods used to clean the tweets and corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet classification\n",
    "\n",
    "File names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To read\n",
    "test_tweets_raw = 'datasets/test_nolabel.csv'\n",
    "train_tweets_raw = 'datasets/train.csv'\n",
    "corpus_tweets_2012_xml = 'general-train-tagged-3l.xml'\n",
    "corpus_tweets_2017_xml = 'intertass-train-tagged.xml'\n",
    "emojis_csv = 'emojis.csv'\n",
    "\n",
    "# To generate\n",
    "corpus_tweets_2012_csv = 'general-train-tagged-3l.csv'\n",
    "corpus_tweets_2017_csv = 'intertass-train-tagged.csv'\n",
    "corpus_tweets_csv = 'corpus_tweets_preprocessed.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Pandas and Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets to evaluate: 177\n",
      "Evaluated tweets so far: 411\n"
     ]
    }
   ],
   "source": [
    "tweets_test = pd.read_csv(test_tweets_raw, encoding='utf-8')\n",
    "tweets_train = pd.read_csv(train_tweets_raw, encoding='utf-8')\n",
    "\n",
    "print('Total tweets to evaluate: %d' % len(tweets_test))\n",
    "print('Evaluated tweets so far: %d' % len(tweets_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging\n",
    "\n",
    "Import libraries to read XML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import objectify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import/read most recent corpus (2017):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4 values of sentiment: N, P, NONE, NEU\n",
    "xml = objectify.parse(open(corpus_tweets_2017_xml))\n",
    "root = xml.getroot()\n",
    "general_tweets_corpus_train_2017 = pd.DataFrame(columns=('content', 'polarity'))\n",
    "tweets = root.getchildren()\n",
    "for i in range(0, len(tweets)):\n",
    "    tweet = tweets[i]\n",
    "    row = dict(zip(['content', 'polarity'], [tweet.content.text, tweet.sentiment.polarity.value.text]))\n",
    "    row_s = pd.Series(row)\n",
    "    row_s.name = i\n",
    "    general_tweets_corpus_train_2017 = general_tweets_corpus_train_2017.append(row_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N       418\n",
       "P       318\n",
       "NONE    139\n",
       "NEU     133\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_tweets_corpus_train_2017.polarity.value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Number of tweets to remove\\npositive_to_remove = 318-133\\nnegative_to_remove = 418-133\\npositive_removed = 0\\nnegative_removed = 0\\n\\n# Init balanced version\\ngeneral_tweets_corpus_train_2017_balanced = pd.DataFrame(columns=('content', 'polarity'))\\n\\n# We balance the dataset, to have the same number of positive, negative and neutral polarity\\nfor i, row in general_tweets_corpus_train_2017.iterrows():\\n    if(row.polarity) == 'P':\\n        positive_removed = positive_removed + 1\\n        if(positive_removed > positive_to_remove):\\n            row_p = dict(zip(['content', 'polarity'], [row.content, row.polarity]))\\n            row_s = pd.Series(row_p)\\n            row_s.name = i\\n            general_tweets_corpus_train_2017_balanced = general_tweets_corpus_train_2017_balanced.append(row_s)\\n    if(row.polarity) == 'N':\\n        negative_removed = negative_removed + 1\\n        if(negative_removed > negative_to_remove):\\n            row_p = dict(zip(['content', 'polarity'], [row.content, row.polarity]))\\n            row_s = pd.Series(row_p)\\n            row_s.name = i\\n            general_tweets_corpus_train_2017_balanced = general_tweets_corpus_train_2017_balanced.append(row_s)\\n    if(row.polarity) == 'NEU':\\n        row_p = dict(zip(['content', 'polarity'], [row.content, row.polarity]))\\n        row_s = pd.Series(row_p)\\n        row_s.name = i\\n        general_tweets_corpus_train_2017_balanced = general_tweets_corpus_train_2017_balanced.append(row_s)\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Number of tweets to remove\n",
    "positive_to_remove = 318-133\n",
    "negative_to_remove = 418-133\n",
    "positive_removed = 0\n",
    "negative_removed = 0\n",
    "\n",
    "# Init balanced version\n",
    "general_tweets_corpus_train_2017_balanced = pd.DataFrame(columns=('content', 'polarity'))\n",
    "\n",
    "# We balance the dataset, to have the same number of positive, negative and neutral polarity\n",
    "for i, row in general_tweets_corpus_train_2017.iterrows():\n",
    "    if(row.polarity) == 'P':\n",
    "        positive_removed = positive_removed + 1\n",
    "        if(positive_removed > positive_to_remove):\n",
    "            row_p = dict(zip(['content', 'polarity'], [row.content, row.polarity]))\n",
    "            row_s = pd.Series(row_p)\n",
    "            row_s.name = i\n",
    "            general_tweets_corpus_train_2017_balanced = general_tweets_corpus_train_2017_balanced.append(row_s)\n",
    "    if(row.polarity) == 'N':\n",
    "        negative_removed = negative_removed + 1\n",
    "        if(negative_removed > negative_to_remove):\n",
    "            row_p = dict(zip(['content', 'polarity'], [row.content, row.polarity]))\n",
    "            row_s = pd.Series(row_p)\n",
    "            row_s.name = i\n",
    "            general_tweets_corpus_train_2017_balanced = general_tweets_corpus_train_2017_balanced.append(row_s)\n",
    "    if(row.polarity) == 'NEU':\n",
    "        row_p = dict(zip(['content', 'polarity'], [row.content, row.polarity]))\n",
    "        row_s = pd.Series(row_p)\n",
    "        row_s.name = i\n",
    "        general_tweets_corpus_train_2017_balanced = general_tweets_corpus_train_2017_balanced.append(row_s)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'general_tweets_corpus_train_2017_balanced.polarity.value_counts(normalize=False)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''general_tweets_corpus_train_2017_balanced.polarity.value_counts(normalize=False)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import/read biggest corpus (2012), to concatenate it with the previous one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4 values of sentiment: N, P, NONE, NEU\n",
    "xml = objectify.parse(open(corpus_tweets_2012_xml))\n",
    "root = xml.getroot()\n",
    "general_tweets_corpus_train_2012 = pd.DataFrame(columns=('content', 'polarity'))\n",
    "tweets = root.getchildren()\n",
    "for i in range(0, len(tweets)):\n",
    "    tweet = tweets[i]\n",
    "    row = dict(zip(['content', 'polarity'], [tweet.content.text, tweet.sentiments.polarity.value.text]))\n",
    "    row_s = pd.Series(row)\n",
    "    row_s.name = i\n",
    "    general_tweets_corpus_train_2012 = general_tweets_corpus_train_2012.append(row_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P       2884\n",
       "N       2182\n",
       "NONE    1483\n",
       "NEU      670\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_tweets_corpus_train_2012.polarity.value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''# Number of tweets to remove\n",
    "positive_to_remove = 2884-670\n",
    "negative_to_remove = 2182-670\n",
    "positive_removed = 0\n",
    "negative_removed = 0\n",
    "\n",
    "# Init balanced version\n",
    "general_tweets_corpus_train_2012_balanced = pd.DataFrame(columns=('content', 'polarity'))\n",
    "\n",
    "# We balance the dataset, to have the same number of positive, negative and neutral polarity\n",
    "for i, row in general_tweets_corpus_train_2012.iterrows():\n",
    "    if(row.polarity) == 'P':\n",
    "        positive_removed = positive_removed + 1\n",
    "        if(positive_removed > positive_to_remove):\n",
    "            row_p = dict(zip(['content', 'polarity'], [row.content, row.polarity]))\n",
    "            row_s = pd.Series(row_p)\n",
    "            row_s.name = i\n",
    "            general_tweets_corpus_train_2012_balanced = general_tweets_corpus_train_2012_balanced.append(row_s)\n",
    "    if(row.polarity) == 'N':\n",
    "        negative_removed = negative_removed + 1\n",
    "        if(negative_removed > negative_to_remove):\n",
    "            row_p = dict(zip(['content', 'polarity'], [row.content, row.polarity]))\n",
    "            row_s = pd.Series(row_p)\n",
    "            row_s.name = i\n",
    "            general_tweets_corpus_train_2012_balanced = general_tweets_corpus_train_2012_balanced.append(row_s)\n",
    "    if(row.polarity) == 'NEU':\n",
    "        row_p = dict(zip(['content', 'polarity'], [row.content, row.polarity]))\n",
    "        row_s = pd.Series(row_p)\n",
    "        row_s.name = i\n",
    "        general_tweets_corpus_train_2012_balanced = general_tweets_corpus_train_2012_balanced.append(row_s)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'general_tweets_corpus_train_2012_balanced.polarity.value_counts(normalize=False)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''general_tweets_corpus_train_2012_balanced.polarity.value_counts(normalize=False)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import/read emoji sentiment dataset, to concatenate with the previous ones. Build column `polarity` according to the following criteria:\n",
    "- If sentiment score is between -1 and 0, consider it a **negative** sentiment (`N`).\n",
    "- If sentiment score is between 0 and 0.2, consider it a **neutral** sentiment (`NEU`).\n",
    "- If sentiment score is between 0.2 and 1, consider it a **positive** sentiment (`P`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dass/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/dass/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# Read emojis CSV\n",
    "emoji_dataset = pd.read_csv(emojis_csv, encoding='utf-8')\n",
    "\n",
    "# Init dataframe to append to corpus\n",
    "emoji_corpus = pd.DataFrame(columns=('content', 'polarity'))\n",
    "\n",
    "# Build column 'polarity\n",
    "emoji_dataset['polarity'] = 'NEU'\n",
    "emoji_dataset['polarity'][emoji_dataset.sentiment < 0] = 'N'\n",
    "emoji_dataset['polarity'][emoji_dataset.sentiment > 0.2] = 'P'\n",
    "\n",
    "for i, row in emoji_dataset.iterrows():\n",
    "    new_row = dict(zip(['content', 'polarity'], [chr(int(row.emoji, 16)), row.polarity]))\n",
    "    row_s = pd.Series(new_row)\n",
    "    row_s.name = i\n",
    "    emoji_corpus = emoji_corpus.append(row_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P      482\n",
       "NEU    170\n",
       "N       99\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_corpus.polarity.value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate general corpus dataset with 2017 one, to have a better result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_corpus = pd.concat([\n",
    "        general_tweets_corpus_train_2012,\n",
    "        general_tweets_corpus_train_2017,\n",
    "        emoji_corpus\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove tweets with polarity 'NONE'\n",
    "tweets_corpus = tweets_corpus.query('polarity != \"NONE\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P      0.500816\n",
       "N      0.366911\n",
       "NEU    0.132273\n",
       "Name: polarity, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.polarity.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import regex tools\n",
    "import re\n",
    "\n",
    "# Build emoji regex\n",
    "emoji_string = '|'.join(emoji_corpus['content'])\n",
    "emoji_regex = re.compile(r'(%s)' % emoji_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>‚Äú@LydiOrtegaRodrg: @David_Busta Jo David... Yo...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Ayay quiero grrabar un trocito de Drown con el...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>üêô</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5272</th>\n",
       "      <td>¬´La Costa del Sol tiene una oferta renovada co...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5721</th>\n",
       "      <td>Me gusta esta foto ;-)) @eliasbendodo @javiera...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>Texto √≠ntegro del Manifiesto \"Yo s√≠ estuve all...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3854</th>\n",
       "      <td>Delenda est Carthago, como dec√≠a el gran Cat√≥n...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Jam√°s voy a discotecas. Hay que dejar algo par...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>Shakira gan√≥ ayer 2 Premios 40: Artista latina...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>Las hemerotecas/videotecas/fonotecas perseguir...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content polarity\n",
       "4843  ‚Äú@LydiOrtegaRodrg: @David_Busta Jo David... Yo...        P\n",
       "621   Ayay quiero grrabar un trocito de Drown con el...        N\n",
       "398                                                   üêô        P\n",
       "5272  ¬´La Costa del Sol tiene una oferta renovada co...        P\n",
       "5721  Me gusta esta foto ;-)) @eliasbendodo @javiera...        P\n",
       "1201  Texto √≠ntegro del Manifiesto \"Yo s√≠ estuve all...      NEU\n",
       "3854  Delenda est Carthago, como dec√≠a el gran Cat√≥n...        P\n",
       "4998  Jam√°s voy a discotecas. Hay que dejar algo par...        N\n",
       "391   Shakira gan√≥ ayer 2 Premios 40: Artista latina...        P\n",
       "1576  Las hemerotecas/videotecas/fonotecas perseguir...        N"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus tweets: 7356\n"
     ]
    }
   ],
   "source": [
    "print('Total corpus tweets: %d' % len(tweets_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "We made ourselves a function for cleaning the data from the tweets (links, mentions...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cleaner import clean_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we clean the train and test data with the previous function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_corpus = clean_tweets(tweets_corpus, 'content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus tweets after cleaning: 7356\n"
     ]
    }
   ],
   "source": [
    "print('Total corpus tweets after cleaning: %d' % len(tweets_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5693</th>\n",
       "      <td>Gracias!!!! Mil besos</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>Si Rajoy no presentara Reforma Laboral se dir√≠...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2403</th>\n",
       "      <td>Mira que lo he pensado, pero estoy muy poco d...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>‚ôö</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3964</th>\n",
       "      <td>Rajoy y Rubalcaba se ver√°n el pr√≥ximo mi√©rcole...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>... para comunicar bien. 4 Preparar buen comie...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3448</th>\n",
       "      <td>Un nuevo aliciente para comprar los s√°bados Ex...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>Me gustaron los mensajes del Rey y Moren√©s a l...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6155</th>\n",
       "      <td>La sentencia de Matas y Alemani es demoledora ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6899</th>\n",
       "      <td>;) RT : cuando puedas verlo :D miralo cuando p...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content polarity\n",
       "5693                              Gracias!!!! Mil besos        P\n",
       "6431  Si Rajoy no presentara Reforma Laboral se dir√≠...        N\n",
       "2403   Mira que lo he pensado, pero estoy muy poco d...        N\n",
       "313                                                  ‚ôö       NEU\n",
       "3964  Rajoy y Rubalcaba se ver√°n el pr√≥ximo mi√©rcole...        P\n",
       "1798  ... para comunicar bien. 4 Preparar buen comie...        P\n",
       "3448  Un nuevo aliciente para comprar los s√°bados Ex...        P\n",
       "1924  Me gustaron los mensajes del Rey y Moren√©s a l...        P\n",
       "6155  La sentencia de Matas y Alemani es demoledora ...        N\n",
       "6899  ;) RT : cuando puedas verlo :D miralo cuando p...        P"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export corpus tweets as CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_corpus.to_csv(corpus_tweets_csv, encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
